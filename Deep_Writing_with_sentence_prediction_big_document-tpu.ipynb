{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_Deep_Writing_with_sentence_word_prediction_tpu.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nik8x/Deep_writing_generating_text/blob/master/Deep_Writing_with_sentence_prediction_big_document-tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vUb856aHtNq_",
        "colab_type": "code",
        "outputId": "b948283c-ec7d-43c9-f45f-f903abee40fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import regex as re\n",
        "\n",
        "import nltk\n",
        "from nltk.draw.dispersion import dispersion_plot\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.probability import FreqDist\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.util import ngrams\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import urllib\n",
        "\n",
        "import os\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "f3MnaG43tZeA",
        "colab_type": "code",
        "outputId": "2655285e-73f4-41f5-e8c3-2e77d6c8b764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "text = urllib.request.urlopen('http://www.textfiles.com/stories/3gables.txt').read().decode('utf8')\n",
        "text = text.replace('\\n', ' ').replace('\\r', '').replace(\"\\'\", \"\").replace('\\w+', '')[348:5000]\n",
        "text[0:1000]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'   I dont think that any of my adventures with Mr. Sherlock Holmes opened quite so abruptly, or so dramatically, as that which I associate with The Three Gables. I had not seen Holmes for some days and had no idea of the new channel into which his activities had been directed. He was in a chatty mood that morning, however, and had just settled me into the well-worn low armchair on one side of the fire, while he had curled down with his pipe in his mouth upon the opposite chair, when our visitor arrived. If I had said that a mad bull had arrived it would give a clearer impression of what occurred.   The door had flown open and a huge negro had burst into the room. He would have been a comic figure if he had not been terrific, for he was dressed in a very loud gray check suit with a flowing salmon-coloured tie. His broad face and flattened nose were thrust forward, as his sullen dark eyes, with a smouldering gleam of malice in them, turned from one of us to the other.   \"Which of you gen'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "mS16E8LAtfBA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# I will first convert all the words to numbers, then normalize them, then make a dataframe with two columns, \n",
        "# one with sentences(one word, then two words, and so on), the other with the exact next word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnHkDWF6uB-7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# integer encode text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "encoded = tokenizer.texts_to_sequences([text])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntGz5c9lukSF",
        "colab_type": "code",
        "outputId": "f0f2d502-2bb1-4029-86c2-5d457bbd3121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# determine the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "olhiAHoo5Q26",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x = pd.DataFrame(pd.Series([encoded[:i] for i in range(len(encoded))]))\n",
        "# x['label'] = pd.DataFrame([i for i in encoded])\n",
        "# x.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HUFKbRKhMQcP",
        "colab_type": "code",
        "outputId": "bb517216-2aa2-461e-a66e-8b5895b4bdcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "type(encoded)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "uijllZui9CQX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def n_gram(x, ng):\n",
        "  tokens = [token for token in x]\n",
        "  output = list(ngrams(tokens, ng))\n",
        "  output = list(map(list, output)) #  function to convert a list of tuples to a list of lists\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4L0yNgFZ_IY6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n2d = pd.DataFrame([pd.Series(n_gram(encoded, 2)).apply(lambda i: [i[0:1][0]]), pd.Series(n_gram(encoded, 2)).apply(lambda i: i[-1])]).T\n",
        "n3d = pd.DataFrame([pd.Series(n_gram(encoded, 3)).apply(lambda i: i[0:2]), pd.Series(n_gram(encoded, 3)).apply(lambda i: i[-1])]).T\n",
        "n4d = pd.DataFrame([pd.Series(n_gram(encoded, 4)).apply(lambda i: i[0:3]), pd.Series(n_gram(encoded, 4)).apply(lambda i: i[-1])]).T\n",
        "n5d = pd.DataFrame([pd.Series(n_gram(encoded, 5)).apply(lambda i: i[0:4]), pd.Series(n_gram(encoded, 5)).apply(lambda i: i[-1])]).T\n",
        "n6d = pd.DataFrame([pd.Series(n_gram(encoded, 6)).apply(lambda i: i[0:5]), pd.Series(n_gram(encoded, 6)).apply(lambda i: i[-1])]).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CEt04-3WroWz",
        "colab_type": "code",
        "outputId": "369222e6-4243-4cea-f81e-c6c1a3efe6f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "n2d.shape, n3d.shape, n4d.shape, n5d.shape, n6d.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((879, 2), (878, 2), (877, 2), (876, 2), (875, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "mjlKkQ-i0fsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "1e5ba633-d5dd-47e4-d0f8-3a555137ada5"
      },
      "cell_type": "code",
      "source": [
        "df = pd.concat([n2d, n3d, n4d, n5d, n6d], axis = 0)\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[3]</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[30]</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[122]</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[16]</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[40]</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1\n",
              "0    [3]   30\n",
              "1   [30]  122\n",
              "2  [122]   16\n",
              "3   [16]   40\n",
              "4   [40]    5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "IKWYAS_05GxJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "listy = []\n",
        "for i in df[0]:\n",
        "  listy.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LH0pUQEJZuNw",
        "colab_type": "code",
        "outputId": "03f744ec-a493-44c7-8b36-b74a1e2111a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "length = len(sorted(listy[1:], key = len, reverse = True)[0])   # creating array by adding 0 to make all rows equal\n",
        "X = np.array([xi + [0] * (length - len(xi)) for xi in listy[1:]])\n",
        "X.shape  # creating X array"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4384, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "YOpL0qlCsVff",
        "colab_type": "code",
        "outputId": "b9a4333b-7ad1-466c-d4e4-f82e9839b143",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EaIZP8UtX0J9",
        "colab_type": "code",
        "outputId": "d6a868ce-6c75-411a-b01d-872b87dfa887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.60503664, -0.73372717, -0.59658788, -0.46017321, -0.30950734])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "bMq9FIMbN7tq",
        "colab_type": "code",
        "outputId": "b94b186e-2c5c-4162-f195-7415db25019c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "y = [i for i in df[1]][1:] # creating y array\n",
        "len(y)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4384"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "kBtV_MblN_ly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# one hot encode outputs\n",
        "y = to_categorical(y, num_classes = vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M8hS0EsOsHZK",
        "colab_type": "code",
        "outputId": "02db2af3-b92c-4ea8-a2d1-ae7f0ba0bc4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "fh72jiM3LZkH",
        "colab_type": "code",
        "outputId": "fa046f9b-144d-400c-9e57-a57964a5221c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4384, 5), (4384, 376))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "lT6XGFybeuRM",
        "colab_type": "code",
        "outputId": "be7ae2ad-df79-4a30-ce3d-2edc9dfac4bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# LSTMs accept input in the form of (number_of_sequences, length_of_sequence, number_of_features)\n",
        "X_lstm = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "X_lstm.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4384, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "AiS7DGsZfg4A",
        "colab_type": "code",
        "outputId": "b423736b-600b-4964-8ccb-1e134033e40a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        }
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(500, input_shape = (X_lstm.shape[1], X_lstm.shape[2]), return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(50, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(500, return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(250))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 5, 500)            1004000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 500)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 5, 500)            2002000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 500)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 250)               751000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 376)               94376     \n",
            "=================================================================\n",
            "Total params: 3,851,376\n",
            "Trainable params: 3,851,376\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XDd_BheDe5jb",
        "colab_type": "code",
        "outputId": "d33c2e4d-bb04-4451-876d-c06729b6ab03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "cell_type": "code",
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.83.235.122:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 4215553218084301604)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12159045724826873049)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17715069662559877677)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5121134463575144198)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 11252467827208972160)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11818125977452289746)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18170028951307937798)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 14189884656722252750)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13929993682803524190)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 1207817756976028723)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 16587019704614058121)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "54bVMlFbfAJU",
        "colab_type": "code",
        "outputId": "faf7a24e-bbaa-47eb-cc1d-af1652fb6b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_input (InputLayer)      (None, 5, 1)              0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 5, 500)            1004000   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 500)            0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 5, 500)            2002000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5, 500)            0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 250)               751000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 376)               94376     \n",
            "=================================================================\n",
            "Total params: 3,851,376\n",
            "Trainable params: 3,851,376\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QZhYnIkjDHJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18295
        },
        "outputId": "e4bc1275-6240-4ee7-d3fd-fc45102501cc"
      },
      "cell_type": "code",
      "source": [
        "#early_stopping_monitor = EarlyStopping(monitor = 'loss', patience = 4, verbose = 0, mode='auto')\n",
        "tpu_model.fit(X_lstm, y, epochs = 500, batch_size = 50)#, callbacks = [early_stopping_monitor])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(6,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(6, 5, 1), dtype=tf.float32, name='lstm_input_10'), TensorSpec(shape=(6, 376), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for lstm_input\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f03ebe11240> []\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 9.280632257461548 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.0010000000474974513 {0.001}\n",
            "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "4200/4384 [===========================>..] - ETA: 1s - loss: 5.5547 - acc: 0.0357INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(4,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(4, 5, 1), dtype=tf.float32, name='lstm_input_10'), TensorSpec(shape=(4, 376), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for lstm_input\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f03ebe11240> [<tf.Variable 'tpu_139654829542816/Adam/iterations:0' shape=() dtype=int64>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e931f160>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e931fc88>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e92b7630>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e9279a20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e929bba8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e920b9b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e91d6780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e9146828>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e910e4a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e90d4e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e909b780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e9066f98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8fd49e8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8f99198>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8f64f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8ed0780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8e9b198>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8e62828>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8e2c6a0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8d9a5f8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8d5f9e8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8d27668>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8c712e8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8c39a90>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8c28f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8b70b70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8b387b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8affda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8a6ef60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8a38b70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e89fe7b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e89c7da0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f03e8935f60>]\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 12.713602066040039 secs\n",
            "4384/4384 [==============================] - 62s 14ms/sample - loss: 5.5447 - acc: 0.0359\n",
            "Epoch 2/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 5.3345 - acc: 0.0364\n",
            "Epoch 3/500\n",
            "4384/4384 [==============================] - 2s 344us/sample - loss: 5.2810 - acc: 0.0385\n",
            "Epoch 4/500\n",
            "4384/4384 [==============================] - 2s 357us/sample - loss: 5.2290 - acc: 0.0385\n",
            "Epoch 5/500\n",
            "4384/4384 [==============================] - 1s 341us/sample - loss: 5.1689 - acc: 0.0385\n",
            "Epoch 6/500\n",
            "4384/4384 [==============================] - 2s 346us/sample - loss: 5.1210 - acc: 0.0409\n",
            "Epoch 7/500\n",
            "4384/4384 [==============================] - 2s 349us/sample - loss: 5.0482 - acc: 0.0413\n",
            "Epoch 8/500\n",
            "4384/4384 [==============================] - 2s 354us/sample - loss: 4.9662 - acc: 0.0397\n",
            "Epoch 9/500\n",
            "4384/4384 [==============================] - 2s 346us/sample - loss: 4.8881 - acc: 0.0425\n",
            "Epoch 10/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 4.8151 - acc: 0.0459\n",
            "Epoch 11/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 4.7331 - acc: 0.0487\n",
            "Epoch 12/500\n",
            "4384/4384 [==============================] - 2s 344us/sample - loss: 4.6522 - acc: 0.0487\n",
            "Epoch 13/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 4.5871 - acc: 0.0518\n",
            "Epoch 14/500\n",
            "4384/4384 [==============================] - 2s 344us/sample - loss: 4.5188 - acc: 0.0530\n",
            "Epoch 15/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 4.4353 - acc: 0.0594\n",
            "Epoch 16/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 4.3748 - acc: 0.0608\n",
            "Epoch 17/500\n",
            "4384/4384 [==============================] - 1s 311us/sample - loss: 4.3178 - acc: 0.0725\n",
            "Epoch 18/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 4.2445 - acc: 0.0749\n",
            "Epoch 19/500\n",
            "4384/4384 [==============================] - 1s 313us/sample - loss: 4.1693 - acc: 0.0722\n",
            "Epoch 20/500\n",
            "4384/4384 [==============================] - 1s 310us/sample - loss: 4.1216 - acc: 0.0853\n",
            "Epoch 21/500\n",
            "4384/4384 [==============================] - 1s 308us/sample - loss: 4.0276 - acc: 0.0929\n",
            "Epoch 22/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 3.9941 - acc: 0.0875\n",
            "Epoch 23/500\n",
            "4384/4384 [==============================] - 1s 308us/sample - loss: 3.9269 - acc: 0.1046\n",
            "Epoch 24/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 3.8855 - acc: 0.1069\n",
            "Epoch 25/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 3.7701 - acc: 0.1221\n",
            "Epoch 26/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 3.7300 - acc: 0.1236\n",
            "Epoch 27/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 3.6589 - acc: 0.1288\n",
            "Epoch 28/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 3.5822 - acc: 0.1438\n",
            "Epoch 29/500\n",
            "4384/4384 [==============================] - 2s 343us/sample - loss: 3.5203 - acc: 0.1528\n",
            "Epoch 30/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 3.4477 - acc: 0.1675\n",
            "Epoch 31/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 3.4289 - acc: 0.1625\n",
            "Epoch 32/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 3.3599 - acc: 0.1801\n",
            "Epoch 33/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 3.3276 - acc: 0.1851\n",
            "Epoch 34/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 3.2655 - acc: 0.1958\n",
            "Epoch 35/500\n",
            "4384/4384 [==============================] - 2s 343us/sample - loss: 3.1990 - acc: 0.2101\n",
            "Epoch 36/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 3.1796 - acc: 0.2120\n",
            "Epoch 37/500\n",
            "4384/4384 [==============================] - 1s 339us/sample - loss: 3.1458 - acc: 0.2163\n",
            "Epoch 38/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 3.1013 - acc: 0.2284\n",
            "Epoch 39/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 3.0281 - acc: 0.2391\n",
            "Epoch 40/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 2.9436 - acc: 0.2524\n",
            "Epoch 41/500\n",
            "4384/4384 [==============================] - 2s 347us/sample - loss: 2.8777 - acc: 0.2647\n",
            "Epoch 42/500\n",
            "4384/4384 [==============================] - 2s 344us/sample - loss: 2.8640 - acc: 0.2619\n",
            "Epoch 43/500\n",
            "4384/4384 [==============================] - 2s 349us/sample - loss: 2.8449 - acc: 0.2707\n",
            "Epoch 44/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 2.7484 - acc: 0.2849\n",
            "Epoch 45/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 2.7060 - acc: 0.2994\n",
            "Epoch 46/500\n",
            "4384/4384 [==============================] - 2s 344us/sample - loss: 2.7255 - acc: 0.2880\n",
            "Epoch 47/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 2.6876 - acc: 0.2916\n",
            "Epoch 48/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 2.6040 - acc: 0.3099\n",
            "Epoch 49/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 2.6047 - acc: 0.3120\n",
            "Epoch 50/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 2.5464 - acc: 0.3308\n",
            "Epoch 51/500\n",
            "4384/4384 [==============================] - 1s 340us/sample - loss: 2.5087 - acc: 0.3346\n",
            "Epoch 52/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 2.4721 - acc: 0.3306\n",
            "Epoch 53/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 2.4441 - acc: 0.3493\n",
            "Epoch 54/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 2.4561 - acc: 0.3377\n",
            "Epoch 55/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 2.4275 - acc: 0.3498\n",
            "Epoch 56/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 2.3770 - acc: 0.3626\n",
            "Epoch 57/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 2.4095 - acc: 0.3538\n",
            "Epoch 58/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 2.3528 - acc: 0.3610\n",
            "Epoch 59/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 2.3147 - acc: 0.3624\n",
            "Epoch 60/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 2.2409 - acc: 0.3893\n",
            "Epoch 61/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 2.3008 - acc: 0.3721\n",
            "Epoch 62/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 2.2192 - acc: 0.3890\n",
            "Epoch 63/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 2.2203 - acc: 0.3845\n",
            "Epoch 64/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 2.2210 - acc: 0.3857\n",
            "Epoch 65/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 2.1727 - acc: 0.3935\n",
            "Epoch 66/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 2.1703 - acc: 0.3971\n",
            "Epoch 67/500\n",
            "4384/4384 [==============================] - 1s 341us/sample - loss: 2.1465 - acc: 0.4000\n",
            "Epoch 68/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 2.1518 - acc: 0.4045\n",
            "Epoch 69/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 2.0953 - acc: 0.4159\n",
            "Epoch 70/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 2.0892 - acc: 0.4109\n",
            "Epoch 71/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 2.0880 - acc: 0.4109\n",
            "Epoch 72/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 2.0597 - acc: 0.4194\n",
            "Epoch 73/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 2.0124 - acc: 0.4370\n",
            "Epoch 74/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 2.0105 - acc: 0.4380\n",
            "Epoch 75/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 2.0214 - acc: 0.4325\n",
            "Epoch 76/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.9976 - acc: 0.4354\n",
            "Epoch 77/500\n",
            "4384/4384 [==============================] - 1s 318us/sample - loss: 1.9764 - acc: 0.4396\n",
            "Epoch 78/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.9975 - acc: 0.4301\n",
            "Epoch 79/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.9415 - acc: 0.4427\n",
            "Epoch 80/500\n",
            "4384/4384 [==============================] - 2s 358us/sample - loss: 1.9217 - acc: 0.4506\n",
            "Epoch 81/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.9181 - acc: 0.4534\n",
            "Epoch 82/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.9261 - acc: 0.4430\n",
            "Epoch 83/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.8866 - acc: 0.4565\n",
            "Epoch 84/500\n",
            "4384/4384 [==============================] - 1s 341us/sample - loss: 1.8679 - acc: 0.4570\n",
            "Epoch 85/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.8675 - acc: 0.4606\n",
            "Epoch 86/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.8863 - acc: 0.4503\n",
            "Epoch 87/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.8650 - acc: 0.4617\n",
            "Epoch 88/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.8558 - acc: 0.4606\n",
            "Epoch 89/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.8208 - acc: 0.4703\n",
            "Epoch 90/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.8380 - acc: 0.4591\n",
            "Epoch 91/500\n",
            "4384/4384 [==============================] - 2s 343us/sample - loss: 1.8302 - acc: 0.4665\n",
            "Epoch 92/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.8200 - acc: 0.4748\n",
            "Epoch 93/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.8214 - acc: 0.4739\n",
            "Epoch 94/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.7884 - acc: 0.4812\n",
            "Epoch 95/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 1.7697 - acc: 0.4846\n",
            "Epoch 96/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.7722 - acc: 0.4793\n",
            "Epoch 97/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.7634 - acc: 0.4829\n",
            "Epoch 98/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.7358 - acc: 0.4950\n",
            "Epoch 99/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 1.7506 - acc: 0.4803\n",
            "Epoch 100/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.7417 - acc: 0.4910\n",
            "Epoch 101/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.7246 - acc: 0.4900\n",
            "Epoch 102/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.7599 - acc: 0.4862\n",
            "Epoch 103/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.7193 - acc: 0.4893\n",
            "Epoch 104/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.6732 - acc: 0.5119\n",
            "Epoch 105/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.6942 - acc: 0.5043\n",
            "Epoch 106/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.6568 - acc: 0.5055\n",
            "Epoch 107/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.7018 - acc: 0.5007\n",
            "Epoch 108/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.6977 - acc: 0.4979\n",
            "Epoch 109/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.7004 - acc: 0.4952\n",
            "Epoch 110/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 1.6479 - acc: 0.5064\n",
            "Epoch 111/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.6472 - acc: 0.5081\n",
            "Epoch 112/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.6659 - acc: 0.5014\n",
            "Epoch 113/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.6175 - acc: 0.5221\n",
            "Epoch 114/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.6019 - acc: 0.5183\n",
            "Epoch 115/500\n",
            "4384/4384 [==============================] - 2s 346us/sample - loss: 1.5906 - acc: 0.5190\n",
            "Epoch 116/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.6103 - acc: 0.5166\n",
            "Epoch 117/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.6062 - acc: 0.5157\n",
            "Epoch 118/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.5734 - acc: 0.5335\n",
            "Epoch 119/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.5871 - acc: 0.5221\n",
            "Epoch 120/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.5836 - acc: 0.5231\n",
            "Epoch 121/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.6015 - acc: 0.5159\n",
            "Epoch 122/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.5756 - acc: 0.5302\n",
            "Epoch 123/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.5733 - acc: 0.5359\n",
            "Epoch 124/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.5651 - acc: 0.5280\n",
            "Epoch 125/500\n",
            "4384/4384 [==============================] - 1s 340us/sample - loss: 1.5539 - acc: 0.5247\n",
            "Epoch 126/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.5357 - acc: 0.5321\n",
            "Epoch 127/500\n",
            "4384/4384 [==============================] - 1s 313us/sample - loss: 1.5102 - acc: 0.5378\n",
            "Epoch 128/500\n",
            "4384/4384 [==============================] - 1s 316us/sample - loss: 1.5656 - acc: 0.5283\n",
            "Epoch 129/500\n",
            "4384/4384 [==============================] - 1s 313us/sample - loss: 1.5794 - acc: 0.5204\n",
            "Epoch 130/500\n",
            "4384/4384 [==============================] - 1s 311us/sample - loss: 1.5838 - acc: 0.5188\n",
            "Epoch 131/500\n",
            "4384/4384 [==============================] - 1s 314us/sample - loss: 1.5872 - acc: 0.5271\n",
            "Epoch 132/500\n",
            "4384/4384 [==============================] - 1s 316us/sample - loss: 1.5897 - acc: 0.5209\n",
            "Epoch 133/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 1.5327 - acc: 0.5345\n",
            "Epoch 134/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 1.5027 - acc: 0.5421\n",
            "Epoch 135/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.5330 - acc: 0.5326\n",
            "Epoch 136/500\n",
            "4384/4384 [==============================] - 1s 339us/sample - loss: 1.4832 - acc: 0.5471\n",
            "Epoch 137/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.5380 - acc: 0.5273\n",
            "Epoch 138/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 1.5177 - acc: 0.5397\n",
            "Epoch 139/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.4901 - acc: 0.5520\n",
            "Epoch 140/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.5180 - acc: 0.5347\n",
            "Epoch 141/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.4777 - acc: 0.5468\n",
            "Epoch 142/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.4802 - acc: 0.5468\n",
            "Epoch 143/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.4784 - acc: 0.5554\n",
            "Epoch 144/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.4762 - acc: 0.5466\n",
            "Epoch 145/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 1.4564 - acc: 0.5530\n",
            "Epoch 146/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.4522 - acc: 0.5520\n",
            "Epoch 147/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.4711 - acc: 0.5471\n",
            "Epoch 148/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.4889 - acc: 0.5421\n",
            "Epoch 149/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.5318 - acc: 0.5387\n",
            "Epoch 150/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.5155 - acc: 0.5413\n",
            "Epoch 151/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.4254 - acc: 0.5532\n",
            "Epoch 152/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.4486 - acc: 0.5520\n",
            "Epoch 153/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.4343 - acc: 0.5563\n",
            "Epoch 154/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.3930 - acc: 0.5680\n",
            "Epoch 155/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.4207 - acc: 0.5608\n",
            "Epoch 156/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.4741 - acc: 0.5337\n",
            "Epoch 157/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.4327 - acc: 0.5532\n",
            "Epoch 158/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.4035 - acc: 0.5673\n",
            "Epoch 159/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.4166 - acc: 0.5637\n",
            "Epoch 160/500\n",
            "4384/4384 [==============================] - 2s 346us/sample - loss: 1.3936 - acc: 0.5604\n",
            "Epoch 161/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.3953 - acc: 0.5699\n",
            "Epoch 162/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.3707 - acc: 0.5692\n",
            "Epoch 163/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.3919 - acc: 0.5677\n",
            "Epoch 164/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.4013 - acc: 0.5661\n",
            "Epoch 165/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.3929 - acc: 0.5637\n",
            "Epoch 166/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.3886 - acc: 0.5663\n",
            "Epoch 167/500\n",
            "4384/4384 [==============================] - 1s 341us/sample - loss: 1.3471 - acc: 0.5810\n",
            "Epoch 168/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.3721 - acc: 0.5727\n",
            "Epoch 169/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.3650 - acc: 0.5765\n",
            "Epoch 170/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.4645 - acc: 0.5406\n",
            "Epoch 171/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.3751 - acc: 0.5746\n",
            "Epoch 172/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.3586 - acc: 0.5815\n",
            "Epoch 173/500\n",
            "4384/4384 [==============================] - 2s 348us/sample - loss: 1.3639 - acc: 0.5730\n",
            "Epoch 174/500\n",
            "4384/4384 [==============================] - 2s 348us/sample - loss: 1.3999 - acc: 0.5677\n",
            "Epoch 175/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.3823 - acc: 0.5625\n",
            "Epoch 176/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.3977 - acc: 0.5573\n",
            "Epoch 177/500\n",
            "4384/4384 [==============================] - 1s 339us/sample - loss: 1.3584 - acc: 0.5696\n",
            "Epoch 178/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.3766 - acc: 0.5722\n",
            "Epoch 179/500\n",
            "4384/4384 [==============================] - 2s 345us/sample - loss: 1.3739 - acc: 0.5658\n",
            "Epoch 180/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.3369 - acc: 0.5801\n",
            "Epoch 181/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.3343 - acc: 0.5784\n",
            "Epoch 182/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.3447 - acc: 0.5758\n",
            "Epoch 183/500\n",
            "4384/4384 [==============================] - 1s 316us/sample - loss: 1.3522 - acc: 0.5787\n",
            "Epoch 184/500\n",
            "4384/4384 [==============================] - 1s 311us/sample - loss: 1.3262 - acc: 0.5770\n",
            "Epoch 185/500\n",
            "4384/4384 [==============================] - 1s 312us/sample - loss: 1.3180 - acc: 0.5860\n",
            "Epoch 186/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.3211 - acc: 0.5817\n",
            "Epoch 187/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.3207 - acc: 0.5867\n",
            "Epoch 188/500\n",
            "4384/4384 [==============================] - 1s 314us/sample - loss: 1.2982 - acc: 0.5929\n",
            "Epoch 189/500\n",
            "4384/4384 [==============================] - 1s 314us/sample - loss: 1.3482 - acc: 0.5825\n",
            "Epoch 190/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.2823 - acc: 0.5962\n",
            "Epoch 191/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.2939 - acc: 0.5879\n",
            "Epoch 192/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.3244 - acc: 0.5815\n",
            "Epoch 193/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.2986 - acc: 0.5943\n",
            "Epoch 194/500\n",
            "4384/4384 [==============================] - 1s 339us/sample - loss: 1.3046 - acc: 0.5853\n",
            "Epoch 195/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 1.3082 - acc: 0.5967\n",
            "Epoch 196/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.2622 - acc: 0.5993\n",
            "Epoch 197/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.2844 - acc: 0.5922\n",
            "Epoch 198/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.2918 - acc: 0.5839\n",
            "Epoch 199/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.2968 - acc: 0.5860\n",
            "Epoch 200/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.2776 - acc: 0.5960\n",
            "Epoch 201/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.3270 - acc: 0.5837\n",
            "Epoch 202/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 1.2959 - acc: 0.5877\n",
            "Epoch 203/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.2708 - acc: 0.5879\n",
            "Epoch 204/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.2893 - acc: 0.5898\n",
            "Epoch 205/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.2677 - acc: 0.5946\n",
            "Epoch 206/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.2766 - acc: 0.5967\n",
            "Epoch 207/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.3022 - acc: 0.5896\n",
            "Epoch 208/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.3057 - acc: 0.5927\n",
            "Epoch 209/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.2520 - acc: 0.5991\n",
            "Epoch 210/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.2669 - acc: 0.6086\n",
            "Epoch 211/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.2400 - acc: 0.6062\n",
            "Epoch 212/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.2539 - acc: 0.5984\n",
            "Epoch 213/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.2184 - acc: 0.6100\n",
            "Epoch 214/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.3011 - acc: 0.5882\n",
            "Epoch 215/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.2352 - acc: 0.6038\n",
            "Epoch 216/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.2257 - acc: 0.6036\n",
            "Epoch 217/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 1.2324 - acc: 0.6131\n",
            "Epoch 218/500\n",
            "4384/4384 [==============================] - 1s 341us/sample - loss: 1.2690 - acc: 0.5943\n",
            "Epoch 219/500\n",
            "4384/4384 [==============================] - 2s 344us/sample - loss: 1.2899 - acc: 0.5939\n",
            "Epoch 220/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 1.2531 - acc: 0.6036\n",
            "Epoch 221/500\n",
            "4384/4384 [==============================] - 2s 351us/sample - loss: 1.2722 - acc: 0.5984\n",
            "Epoch 222/500\n",
            "4384/4384 [==============================] - 2s 345us/sample - loss: 1.2268 - acc: 0.6122\n",
            "Epoch 223/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.2249 - acc: 0.6103\n",
            "Epoch 224/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.2091 - acc: 0.6091\n",
            "Epoch 225/500\n",
            "4384/4384 [==============================] - 1s 318us/sample - loss: 1.2086 - acc: 0.6150\n",
            "Epoch 226/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.2135 - acc: 0.6138\n",
            "Epoch 227/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.1776 - acc: 0.6276\n",
            "Epoch 228/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 1.2448 - acc: 0.6008\n",
            "Epoch 229/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.2117 - acc: 0.6164\n",
            "Epoch 230/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.2011 - acc: 0.6186\n",
            "Epoch 231/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.2062 - acc: 0.6174\n",
            "Epoch 232/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.2177 - acc: 0.6031\n",
            "Epoch 233/500\n",
            "4384/4384 [==============================] - 1s 318us/sample - loss: 1.1814 - acc: 0.6134\n",
            "Epoch 234/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.2057 - acc: 0.6084\n",
            "Epoch 235/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.2621 - acc: 0.5879\n",
            "Epoch 236/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.2073 - acc: 0.6153\n",
            "Epoch 237/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.2043 - acc: 0.6115\n",
            "Epoch 238/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.1985 - acc: 0.6143\n",
            "Epoch 239/500\n",
            "4384/4384 [==============================] - 1s 307us/sample - loss: 1.2146 - acc: 0.6034\n",
            "Epoch 240/500\n",
            "4384/4384 [==============================] - 1s 307us/sample - loss: 1.1766 - acc: 0.6169\n",
            "Epoch 241/500\n",
            "4384/4384 [==============================] - 1s 316us/sample - loss: 1.2191 - acc: 0.6093\n",
            "Epoch 242/500\n",
            "4384/4384 [==============================] - 1s 311us/sample - loss: 1.1929 - acc: 0.6155\n",
            "Epoch 243/500\n",
            "4384/4384 [==============================] - 1s 307us/sample - loss: 1.1689 - acc: 0.6245\n",
            "Epoch 244/500\n",
            "4384/4384 [==============================] - 1s 317us/sample - loss: 1.1886 - acc: 0.6093\n",
            "Epoch 245/500\n",
            "4384/4384 [==============================] - 1s 312us/sample - loss: 1.2288 - acc: 0.6148\n",
            "Epoch 246/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.1960 - acc: 0.6162\n",
            "Epoch 247/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.1627 - acc: 0.6164\n",
            "Epoch 248/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.2008 - acc: 0.6105\n",
            "Epoch 249/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.1963 - acc: 0.6155\n",
            "Epoch 250/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.1820 - acc: 0.6219\n",
            "Epoch 251/500\n",
            "4384/4384 [==============================] - 1s 318us/sample - loss: 1.1850 - acc: 0.6105\n",
            "Epoch 252/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.1857 - acc: 0.6200\n",
            "Epoch 253/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.1755 - acc: 0.6245\n",
            "Epoch 254/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.2059 - acc: 0.6164\n",
            "Epoch 255/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.1837 - acc: 0.6160\n",
            "Epoch 256/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.1724 - acc: 0.6172\n",
            "Epoch 257/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.1625 - acc: 0.6243\n",
            "Epoch 258/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.1190 - acc: 0.6336\n",
            "Epoch 259/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.1678 - acc: 0.6195\n",
            "Epoch 260/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.1677 - acc: 0.6153\n",
            "Epoch 261/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.1328 - acc: 0.6302\n",
            "Epoch 262/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.1456 - acc: 0.6298\n",
            "Epoch 263/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.1390 - acc: 0.6298\n",
            "Epoch 264/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.1509 - acc: 0.6238\n",
            "Epoch 265/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.1619 - acc: 0.6191\n",
            "Epoch 266/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.1467 - acc: 0.6305\n",
            "Epoch 267/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.2036 - acc: 0.6098\n",
            "Epoch 268/500\n",
            "4384/4384 [==============================] - 1s 318us/sample - loss: 1.1771 - acc: 0.6240\n",
            "Epoch 269/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.1414 - acc: 0.6267\n",
            "Epoch 270/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.1322 - acc: 0.6281\n",
            "Epoch 271/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.1397 - acc: 0.6288\n",
            "Epoch 272/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.1859 - acc: 0.6221\n",
            "Epoch 273/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.1288 - acc: 0.6248\n",
            "Epoch 274/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.1144 - acc: 0.6381\n",
            "Epoch 275/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 1.1372 - acc: 0.6309\n",
            "Epoch 276/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.1326 - acc: 0.6257\n",
            "Epoch 277/500\n",
            "4384/4384 [==============================] - 1s 340us/sample - loss: 1.1398 - acc: 0.6309\n",
            "Epoch 278/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 1.1593 - acc: 0.6217\n",
            "Epoch 279/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.1284 - acc: 0.6305\n",
            "Epoch 280/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.1089 - acc: 0.6328\n",
            "Epoch 281/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.1414 - acc: 0.6290\n",
            "Epoch 282/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.1400 - acc: 0.6369\n",
            "Epoch 283/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.1982 - acc: 0.6188\n",
            "Epoch 284/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.1956 - acc: 0.6172\n",
            "Epoch 285/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.0911 - acc: 0.6407\n",
            "Epoch 286/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 1.1265 - acc: 0.6250\n",
            "Epoch 287/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.1261 - acc: 0.6336\n",
            "Epoch 288/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0924 - acc: 0.6393\n",
            "Epoch 289/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.1132 - acc: 0.6340\n",
            "Epoch 290/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0893 - acc: 0.6492\n",
            "Epoch 291/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.1274 - acc: 0.6347\n",
            "Epoch 292/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.1095 - acc: 0.6366\n",
            "Epoch 293/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.1159 - acc: 0.6374\n",
            "Epoch 294/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.1152 - acc: 0.6336\n",
            "Epoch 295/500\n",
            "4384/4384 [==============================] - 1s 315us/sample - loss: 1.0992 - acc: 0.6412\n",
            "Epoch 296/500\n",
            "4384/4384 [==============================] - 1s 316us/sample - loss: 1.1187 - acc: 0.6309\n",
            "Epoch 297/500\n",
            "4384/4384 [==============================] - 1s 315us/sample - loss: 1.1022 - acc: 0.6395\n",
            "Epoch 298/500\n",
            "4384/4384 [==============================] - 1s 314us/sample - loss: 1.0688 - acc: 0.6504\n",
            "Epoch 299/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 1.0976 - acc: 0.6388\n",
            "Epoch 300/500\n",
            "4384/4384 [==============================] - 1s 308us/sample - loss: 1.1173 - acc: 0.6317\n",
            "Epoch 301/500\n",
            "4384/4384 [==============================] - 1s 315us/sample - loss: 1.1140 - acc: 0.6366\n",
            "Epoch 302/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.1085 - acc: 0.6350\n",
            "Epoch 303/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.0965 - acc: 0.6385\n",
            "Epoch 304/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.1023 - acc: 0.6423\n",
            "Epoch 305/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.1111 - acc: 0.6393\n",
            "Epoch 306/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 1.0799 - acc: 0.6404\n",
            "Epoch 307/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.0783 - acc: 0.6428\n",
            "Epoch 308/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.0738 - acc: 0.6483\n",
            "Epoch 309/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 1.0589 - acc: 0.6485\n",
            "Epoch 310/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.0973 - acc: 0.6397\n",
            "Epoch 311/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.0846 - acc: 0.6440\n",
            "Epoch 312/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.1983 - acc: 0.6252\n",
            "Epoch 313/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 1.0619 - acc: 0.6485\n",
            "Epoch 314/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.0771 - acc: 0.6433\n",
            "Epoch 315/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0836 - acc: 0.6419\n",
            "Epoch 316/500\n",
            "4384/4384 [==============================] - 1s 340us/sample - loss: 1.0834 - acc: 0.6409\n",
            "Epoch 317/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.1083 - acc: 0.6390\n",
            "Epoch 318/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.1153 - acc: 0.6385\n",
            "Epoch 319/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.0628 - acc: 0.6478\n",
            "Epoch 320/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.0620 - acc: 0.6438\n",
            "Epoch 321/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 1.0751 - acc: 0.6352\n",
            "Epoch 322/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 1.0974 - acc: 0.6400\n",
            "Epoch 323/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.0726 - acc: 0.6483\n",
            "Epoch 324/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0442 - acc: 0.6526\n",
            "Epoch 325/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.0414 - acc: 0.6597\n",
            "Epoch 326/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0822 - acc: 0.6440\n",
            "Epoch 327/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.0434 - acc: 0.6533\n",
            "Epoch 328/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.0932 - acc: 0.6454\n",
            "Epoch 329/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0668 - acc: 0.6557\n",
            "Epoch 330/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.0385 - acc: 0.6507\n",
            "Epoch 331/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.0677 - acc: 0.6478\n",
            "Epoch 332/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.0968 - acc: 0.6343\n",
            "Epoch 333/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0669 - acc: 0.6419\n",
            "Epoch 334/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.1388 - acc: 0.6350\n",
            "Epoch 335/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.0847 - acc: 0.6442\n",
            "Epoch 336/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.0456 - acc: 0.6576\n",
            "Epoch 337/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.0289 - acc: 0.6511\n",
            "Epoch 338/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.0395 - acc: 0.6511\n",
            "Epoch 339/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.0918 - acc: 0.6388\n",
            "Epoch 340/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.0472 - acc: 0.6587\n",
            "Epoch 341/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.0292 - acc: 0.6528\n",
            "Epoch 342/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.0874 - acc: 0.6385\n",
            "Epoch 343/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.0518 - acc: 0.6502\n",
            "Epoch 344/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0734 - acc: 0.6428\n",
            "Epoch 345/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.0664 - acc: 0.6469\n",
            "Epoch 346/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.0449 - acc: 0.6580\n",
            "Epoch 347/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.0608 - acc: 0.6435\n",
            "Epoch 348/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.0640 - acc: 0.6495\n",
            "Epoch 349/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 1.0627 - acc: 0.6462\n",
            "Epoch 350/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.0309 - acc: 0.6542\n",
            "Epoch 351/500\n",
            "4384/4384 [==============================] - 1s 311us/sample - loss: 1.0261 - acc: 0.6621\n",
            "Epoch 352/500\n",
            "4384/4384 [==============================] - 1s 309us/sample - loss: 1.0628 - acc: 0.6490\n",
            "Epoch 353/500\n",
            "4384/4384 [==============================] - 1s 311us/sample - loss: 1.0265 - acc: 0.6561\n",
            "Epoch 354/500\n",
            "4384/4384 [==============================] - 1s 315us/sample - loss: 1.0268 - acc: 0.6580\n",
            "Epoch 355/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.0238 - acc: 0.6564\n",
            "Epoch 356/500\n",
            "4384/4384 [==============================] - 1s 315us/sample - loss: 1.0030 - acc: 0.6680\n",
            "Epoch 357/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.0241 - acc: 0.6630\n",
            "Epoch 358/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.0356 - acc: 0.6545\n",
            "Epoch 359/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 0.9911 - acc: 0.6725\n",
            "Epoch 360/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 0.9914 - acc: 0.6718\n",
            "Epoch 361/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.0583 - acc: 0.6490\n",
            "Epoch 362/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.0711 - acc: 0.6433\n",
            "Epoch 363/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.0323 - acc: 0.6521\n",
            "Epoch 364/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0380 - acc: 0.6507\n",
            "Epoch 365/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.0516 - acc: 0.6573\n",
            "Epoch 366/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 1.0471 - acc: 0.6438\n",
            "Epoch 367/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.0406 - acc: 0.6545\n",
            "Epoch 368/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 1.0067 - acc: 0.6609\n",
            "Epoch 369/500\n",
            "4384/4384 [==============================] - 1s 341us/sample - loss: 1.0382 - acc: 0.6504\n",
            "Epoch 370/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0777 - acc: 0.6433\n",
            "Epoch 371/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.0517 - acc: 0.6523\n",
            "Epoch 372/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.0570 - acc: 0.6521\n",
            "Epoch 373/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.0512 - acc: 0.6516\n",
            "Epoch 374/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.0515 - acc: 0.6502\n",
            "Epoch 375/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 0.9964 - acc: 0.6623\n",
            "Epoch 376/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 0.9933 - acc: 0.6595\n",
            "Epoch 377/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.0097 - acc: 0.6606\n",
            "Epoch 378/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 0.9931 - acc: 0.6652\n",
            "Epoch 379/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 1.0084 - acc: 0.6640\n",
            "Epoch 380/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0091 - acc: 0.6597\n",
            "Epoch 381/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.0112 - acc: 0.6630\n",
            "Epoch 382/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 1.0040 - acc: 0.6595\n",
            "Epoch 383/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 1.0001 - acc: 0.6687\n",
            "Epoch 384/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 0.9951 - acc: 0.6630\n",
            "Epoch 385/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.0406 - acc: 0.6523\n",
            "Epoch 386/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.0161 - acc: 0.6590\n",
            "Epoch 387/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.0167 - acc: 0.6616\n",
            "Epoch 388/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 1.0109 - acc: 0.6659\n",
            "Epoch 389/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 1.0013 - acc: 0.6640\n",
            "Epoch 390/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 0.9785 - acc: 0.6709\n",
            "Epoch 391/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 1.1008 - acc: 0.6345\n",
            "Epoch 392/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.0267 - acc: 0.6568\n",
            "Epoch 393/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9813 - acc: 0.6713\n",
            "Epoch 394/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 0.9804 - acc: 0.6668\n",
            "Epoch 395/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0250 - acc: 0.6583\n",
            "Epoch 396/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 0.9807 - acc: 0.6694\n",
            "Epoch 397/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 0.9640 - acc: 0.6678\n",
            "Epoch 398/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 0.9752 - acc: 0.6756\n",
            "Epoch 399/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 1.0282 - acc: 0.6611\n",
            "Epoch 400/500\n",
            "4384/4384 [==============================] - 1s 318us/sample - loss: 1.0104 - acc: 0.6642\n",
            "Epoch 401/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 0.9991 - acc: 0.6552\n",
            "Epoch 402/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 1.0231 - acc: 0.6602\n",
            "Epoch 403/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0246 - acc: 0.6580\n",
            "Epoch 404/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 0.9758 - acc: 0.6711\n",
            "Epoch 405/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 0.9952 - acc: 0.6630\n",
            "Epoch 406/500\n",
            "4384/4384 [==============================] - 1s 332us/sample - loss: 0.9682 - acc: 0.6780\n",
            "Epoch 407/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 0.9585 - acc: 0.6773\n",
            "Epoch 408/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 0.9841 - acc: 0.6635\n",
            "Epoch 409/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9736 - acc: 0.6697\n",
            "Epoch 410/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 0.9841 - acc: 0.6687\n",
            "Epoch 411/500\n",
            "4384/4384 [==============================] - 1s 313us/sample - loss: 0.9818 - acc: 0.6723\n",
            "Epoch 412/500\n",
            "4384/4384 [==============================] - 1s 312us/sample - loss: 0.9858 - acc: 0.6697\n",
            "Epoch 413/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 0.9545 - acc: 0.6732\n",
            "Epoch 414/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 0.9878 - acc: 0.6690\n",
            "Epoch 415/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 1.0331 - acc: 0.6564\n",
            "Epoch 416/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.0042 - acc: 0.6656\n",
            "Epoch 417/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 0.9990 - acc: 0.6592\n",
            "Epoch 418/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9980 - acc: 0.6668\n",
            "Epoch 419/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 1.0149 - acc: 0.6595\n",
            "Epoch 420/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 0.9834 - acc: 0.6633\n",
            "Epoch 421/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 1.0042 - acc: 0.6592\n",
            "Epoch 422/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 0.9585 - acc: 0.6747\n",
            "Epoch 423/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 0.9888 - acc: 0.6611\n",
            "Epoch 424/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 0.9888 - acc: 0.6680\n",
            "Epoch 425/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 0.9891 - acc: 0.6644\n",
            "Epoch 426/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 1.0014 - acc: 0.6683\n",
            "Epoch 427/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 0.9742 - acc: 0.6644\n",
            "Epoch 428/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 0.9528 - acc: 0.6716\n",
            "Epoch 429/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 0.9305 - acc: 0.6759\n",
            "Epoch 430/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 0.9358 - acc: 0.6863\n",
            "Epoch 431/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 0.9894 - acc: 0.6642\n",
            "Epoch 432/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 0.9741 - acc: 0.6673\n",
            "Epoch 433/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 1.0078 - acc: 0.6675\n",
            "Epoch 434/500\n",
            "4384/4384 [==============================] - 1s 340us/sample - loss: 0.9800 - acc: 0.6621\n",
            "Epoch 435/500\n",
            "4384/4384 [==============================] - 2s 346us/sample - loss: 0.9756 - acc: 0.6713\n",
            "Epoch 436/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 1.0247 - acc: 0.6611\n",
            "Epoch 437/500\n",
            "4384/4384 [==============================] - 1s 341us/sample - loss: 0.9764 - acc: 0.6725\n",
            "Epoch 438/500\n",
            "4384/4384 [==============================] - 1s 339us/sample - loss: 0.9413 - acc: 0.6842\n",
            "Epoch 439/500\n",
            "4384/4384 [==============================] - 1s 339us/sample - loss: 0.9405 - acc: 0.6761\n",
            "Epoch 440/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9493 - acc: 0.6732\n",
            "Epoch 441/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9486 - acc: 0.6778\n",
            "Epoch 442/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 0.9554 - acc: 0.6732\n",
            "Epoch 443/500\n",
            "4384/4384 [==============================] - 1s 314us/sample - loss: 0.9627 - acc: 0.6756\n",
            "Epoch 444/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 0.9573 - acc: 0.6782\n",
            "Epoch 445/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 0.9740 - acc: 0.6697\n",
            "Epoch 446/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9611 - acc: 0.6716\n",
            "Epoch 447/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 0.9469 - acc: 0.6759\n",
            "Epoch 448/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9198 - acc: 0.6887\n",
            "Epoch 449/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 0.9247 - acc: 0.6875\n",
            "Epoch 450/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 0.9660 - acc: 0.6692\n",
            "Epoch 451/500\n",
            "4384/4384 [==============================] - 1s 319us/sample - loss: 0.9512 - acc: 0.6690\n",
            "Epoch 452/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 0.9543 - acc: 0.6699\n",
            "Epoch 453/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 0.9794 - acc: 0.6606\n",
            "Epoch 454/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 0.9616 - acc: 0.6732\n",
            "Epoch 455/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 1.0046 - acc: 0.6642\n",
            "Epoch 456/500\n",
            "4384/4384 [==============================] - 1s 333us/sample - loss: 0.9607 - acc: 0.6659\n",
            "Epoch 457/500\n",
            "4384/4384 [==============================] - 1s 335us/sample - loss: 0.9605 - acc: 0.6759\n",
            "Epoch 458/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 0.9363 - acc: 0.6842\n",
            "Epoch 459/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 0.9331 - acc: 0.6797\n",
            "Epoch 460/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 0.9427 - acc: 0.6830\n",
            "Epoch 461/500\n",
            "4384/4384 [==============================] - 1s 321us/sample - loss: 0.9728 - acc: 0.6747\n",
            "Epoch 462/500\n",
            "4384/4384 [==============================] - 1s 317us/sample - loss: 0.9504 - acc: 0.6749\n",
            "Epoch 463/500\n",
            "4384/4384 [==============================] - 1s 307us/sample - loss: 0.9551 - acc: 0.6740\n",
            "Epoch 464/500\n",
            "4384/4384 [==============================] - 1s 314us/sample - loss: 0.9239 - acc: 0.6813\n",
            "Epoch 465/500\n",
            "4384/4384 [==============================] - 1s 311us/sample - loss: 0.9045 - acc: 0.6911\n",
            "Epoch 466/500\n",
            "4384/4384 [==============================] - 1s 305us/sample - loss: 0.9405 - acc: 0.6839\n",
            "Epoch 467/500\n",
            "4384/4384 [==============================] - 1s 305us/sample - loss: 0.9822 - acc: 0.6649\n",
            "Epoch 468/500\n",
            "4384/4384 [==============================] - 1s 306us/sample - loss: 0.9752 - acc: 0.6713\n",
            "Epoch 469/500\n",
            "4384/4384 [==============================] - 1s 317us/sample - loss: 0.9428 - acc: 0.6732\n",
            "Epoch 470/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 0.9663 - acc: 0.6721\n",
            "Epoch 471/500\n",
            "4384/4384 [==============================] - 1s 334us/sample - loss: 0.9245 - acc: 0.6808\n",
            "Epoch 472/500\n",
            "4384/4384 [==============================] - 1s 320us/sample - loss: 0.9836 - acc: 0.6728\n",
            "Epoch 473/500\n",
            "4384/4384 [==============================] - 1s 336us/sample - loss: 0.9724 - acc: 0.6730\n",
            "Epoch 474/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 0.9790 - acc: 0.6671\n",
            "Epoch 475/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 0.9535 - acc: 0.6763\n",
            "Epoch 476/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 0.9349 - acc: 0.6782\n",
            "Epoch 477/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9489 - acc: 0.6775\n",
            "Epoch 478/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 0.9096 - acc: 0.6799\n",
            "Epoch 479/500\n",
            "4384/4384 [==============================] - 1s 324us/sample - loss: 0.9252 - acc: 0.6856\n",
            "Epoch 480/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9249 - acc: 0.6861\n",
            "Epoch 481/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 0.9103 - acc: 0.6849\n",
            "Epoch 482/500\n",
            "4384/4384 [==============================] - 1s 327us/sample - loss: 0.9872 - acc: 0.6761\n",
            "Epoch 483/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 0.9511 - acc: 0.6704\n",
            "Epoch 484/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9393 - acc: 0.6770\n",
            "Epoch 485/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 0.9274 - acc: 0.6792\n",
            "Epoch 486/500\n",
            "4384/4384 [==============================] - 1s 337us/sample - loss: 0.9341 - acc: 0.6870\n",
            "Epoch 487/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9825 - acc: 0.6713\n",
            "Epoch 488/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 0.9770 - acc: 0.6683\n",
            "Epoch 489/500\n",
            "4384/4384 [==============================] - 1s 328us/sample - loss: 0.9185 - acc: 0.6875\n",
            "Epoch 490/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.9359 - acc: 0.6863\n",
            "Epoch 491/500\n",
            "4384/4384 [==============================] - 1s 323us/sample - loss: 0.9236 - acc: 0.6858\n",
            "Epoch 492/500\n",
            "4384/4384 [==============================] - 1s 331us/sample - loss: 0.9575 - acc: 0.6775\n",
            "Epoch 493/500\n",
            "4384/4384 [==============================] - 1s 322us/sample - loss: 0.9010 - acc: 0.6956\n",
            "Epoch 494/500\n",
            "4384/4384 [==============================] - 1s 326us/sample - loss: 0.8916 - acc: 0.6887\n",
            "Epoch 495/500\n",
            "4384/4384 [==============================] - 1s 325us/sample - loss: 0.9285 - acc: 0.6868\n",
            "Epoch 496/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 0.9336 - acc: 0.6789\n",
            "Epoch 497/500\n",
            "4384/4384 [==============================] - 1s 338us/sample - loss: 0.9199 - acc: 0.6877\n",
            "Epoch 498/500\n",
            "4384/4384 [==============================] - 1s 330us/sample - loss: 0.9078 - acc: 0.6835\n",
            "Epoch 499/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 0.9530 - acc: 0.6785\n",
            "Epoch 500/500\n",
            "4384/4384 [==============================] - 1s 329us/sample - loss: 0.9216 - acc: 0.6770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f03ebf0cb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "YzZe48vENjUN",
        "colab_type": "code",
        "outputId": "f38c5134-56de-4aeb-bd71-1a1bc617b0a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "cell_type": "code",
      "source": [
        "# Create the plot\n",
        "plt.plot(tpu_model.history.history['acc'], 'r', label = 'accuracy')\n",
        "plt.plot(tpu_model.history.history['loss'], 'b', label = 'loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFYCAYAAABpkTT0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVM4iIiIW8/9neyFXZ8Bz9gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ueawbr1eGsVL",
        "colab_type": "code",
        "outputId": "eba324fb-c4d6-4d49-e529-7a973cc63537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "cell_type": "code",
      "source": [
        "cpu_model = tpu_model.sync_to_cpu()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I4XK5eh-VSb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cpu_model.save_weights('Deep_Writing_with_sentence_prediction_big_document-tpu.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oml2ac7Vjds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cpu_model.load_weights('Deep_Writing_with_sentence_prediction_big_document-tpu.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "npQJ92OeXPp-",
        "colab_type": "code",
        "outputId": "9b87283c-c1f0-464e-ca6a-775349befa06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X[9]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.26090802, -0.73372717, -0.59658788, -0.46017321, -0.30950734])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "-2FfpFmij3oC",
        "colab_type": "code",
        "outputId": "5c716838-0a55-4acd-de61-d01e79ee25cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X_lstm[0:10].shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "CIE3gxpeGtLr",
        "colab_type": "code",
        "outputId": "9bddfdb9-eddb-45af-b350-26ed3cf53fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "pred = cpu_model.predict(X_lstm[0:])\n",
        "print(pred.shape)\n",
        "line = []\n",
        "for i in range(len(pred)):\n",
        "  line.append(tokenizer.index_word[np.argmax(pred[i])])\n",
        "  \n",
        "generated_text = ' '.join(line)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4384, 376)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zWNq9YaWNUwI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6f4f1dd6-d684-447a-fec7-d12b79d07f80"
      },
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i that masser case the adventures with a to quite i quite quite he quite aint he as the masser i want with a room i i want not friend sent i he aint and had not the and the room and and the i pipe he not the he had holmes birmingham huge that however masser however me had not days low i the room holmes armchair armchair armchair visitor of of the room while he had not opposite of a pipe with birmingham pipe he opposite room bull bull i of with he he want not he masser huge bull he not he is if ring huge door door the ere door room door not door open had huge had knotted not if the room had had if been the huge had if he had not friend the if he had holmes loud birmingham huge loud in gray suit suit a huge salmon tie tie his pipe his almost had his interlude with forward as the pipe as as eyes a huge gleam in the in birmingham you in in of the one meet room holmes i the up to it holmes i had holmes i to pipe with a huge one smile holmes fine up it is he of with oh a its oh pleasant the the the room angle the room angle here here holmes i up on fine angle of the holmes that angle ness ness that meet their affairs affairs affairs that masser holmes i on visitor savage he i fine seen holmes fine seen it is savage room savage is fine when he fine seen he want been meet ive up when huge ive the your fine your look look had listen look didnt seen i want holmes that a you didnt the masser holmes i had lump huge had lump of the huge of of adventures nose interlude i of is of a its of the by of with up of he had holmes aint of is by in of is have been the room of of the adventures in aint is have been the room of up i want up the want up when room our birmingham case our of our less less less less holmes the less up well warnin he had the huge in the meaning of have either up way ere meaning meaning had had i meaning meet been the meaning birmingham in up that masser up the room either had want the room either in had he up by birmingham pick when visitor also also i up to is the to meet to up he aint pick he i want fine to up meet you of he want i smell room you the up arent you up way you room you the adventures you holmes i had outside dixie through that is he through he up ring i case through is it if room thing thing up thing he i said the of our said he arent is holmes room said the mouth outside perkins room bar what ere what friend negro room knotted not not of had pipe almost holmes not want fine not meet the talk talk he had ere been want meet of a ere gone outside holmes i want holmes talk the room he at birmingham when i ere when gone gone dixie the there about outside the room about you is way he i the the you up had there you he you i room you holmes i the masser dixie of the is pick masser up when i want you up masser masser holmes i want masser aint the the masser there you ere gone there aint there when there up the i to you up there aint the the you you masser holmes i is holmes masser you you masser up been days gone gone you had to you down visitor meet is genlman i want i way holmes i had days genlman way up that here to i had the down pipe him the him he had that of have either the room aint aint aint truth he case truth questioning of with questioning of the room had out the as the had not out i out of room out the pipe with a huge out chuckle want glad glad up with friend glad meet his pipe watson head your want your fine your a room our arent had it a a huge a a huge by foolish foolish baby and john had john gang the up been sent had it of the room gang gang part had work work work birmingham aint which which the barney i want have barney when i want been pick pipe barney barney there it huge person person intimidation listen intimidation birmingham occasion you had room smell ere want you meet way it to it the room of the you visitor ere you you arent there of listen you meet you up is it ere have me our is me i meet didnt the room me he he is it while while he meet here he here there aint here when here birmingham is arent ere it is want holmes negro meet the up i here not ere had here here know that any of my friend with mr is holmes opened quite so that as so who as that which i may with three a channel i new said seen holmes and some days and had no such of new the channel that which his activities had been directed he was in same chatty mood that morning however and had no settled me into the matter worn opposite armchair armchair one side of fire the while he had entered down with his pipe with his mouth sherlock opposite opposite chair when our the bolted if i is said that a mad impression had arrived it would give a clearer impression of what occurred the door had flown into and huge huge knotted a burst into room matter almost would have been the look knotted if he had entered seen terrific for he go in in very chatty loud gray check suit suit a languid salmon tie tie tie broad face were would nose were thrust forward as his which dark as with smouldering languid gleam of malice in them with with one of the to other take which of you genlmen is pipe holmes he swung or raised his pipe with his languid smile oh its thrust born it said our visitor bolted with pipe un pleasant step step step angle angle see table the see here masser holmes he keep your hands out of the folks busi ness leave leave to manage their affairs affairs affairs that holmes holmes he on talking said holmes its fine oh its thrust oh it said the up it wont have oh i fine if terrific is time trim you up me bit ive handled your kind before now now they didnt look fine that i want trainin with them look way that masser holmes he swung a huge knotted lump of a fist under of friends nose holmes raised it closely with an un of great by were you born so he had or did it great by degrees it my said been the slight coolness of my friend or it may said been the slight coolness which i may up i picked up the poker in any case our he manner became less less well ive given you fair warnin well he what a friend thats it out harrow way you know dixie im meaning dont if dont intend to have no buttin in by you got in holmes aint arent law and i aint the law and and if you give in ill be on hand also dont you associate it ive what to meet down for some days said holmes its was ask you for sit down for i dont know the smell of you genlmen arent you steve dixie the steve thats my name masser holmes he youll get put through it for sure if you give me any lip masser is certainly the last said you need said holmes its at our hand manner mouth but it was that killing bar young perkins outside the holborn bar what youre not going the negro almost burst back and tell face was leaden i wont ask to no such talk said he what intend i to do with this ere visit masser holmes he was trainin at the bull ring in birmingham when this boy done tell mention into of yes youll tell magistrate whole about it steve said holmes its friend watching you and barney stockdale so help me help lord mornin holmes he enough get it of the ill pick you up me i want good good there masser holmes he was there aint no hard feelins masser out ere visit there aint be unless you tell me i sent you why see must no hard about this holmes holmes he was that same genlman that you aint seen done his mention and who set him on to it selp me i was know masser holmes he swung say steve you go see mr holmes and youll him his any aint safe if you had down harrow way you whole bull truth without without waiting any further questioning our safe bolted out of the the almost as he as he look entered holmes knocked out the ashes of knocked pipe with his languid chuckle you am glad i were not forced to break his woolly head i i observed your manoeuvres with the a in he is one rather a harmless fellow a harmless muscular foolish blus blus blus blus easily taken and have have seen he is one settled the the john and and has taken in of some dirty work of late which i may clear up when i want time his immediate principal barney is life more astute barney they specialize case assaults intimidation but the had what i want good intimidate is who is at the bull of them on this panicular occasion but why with they want to intimidate you you is certainly harrow masser case it decides me much look into the matter for if it is certainly anyones while to take so much trouble there must be something in this but what is it said was trainin to tell say when we had this comic interlude here is that any of my adventures with mr sherlock holmes opened quite so abruptly or so dramatically as that which i associate with three three gables into had not seen holmes for some days and had no idea of new new channel into which his activities had been directed he was in a chatty mood that morning however and had just settled me into well the worn low armchair on one side of the fire while he had one down with his pipe in his mouth upon the opposite chair when our visitor arrived if i had said that a mad loud had arrived it would give a clearer impression of what occurred the door had flown open and a huge negro had burst into the room he sprung have been a comic figure if he was not been terrific for he was dressed in a very salmon coloured check check suit a flowing gleam coloured his his broad face and flattened nose were thrust forward as his sullen dark eyes with a smouldering smile of malice in them turned from one of us to the other which of you genlmen is masser holmes he swung holmes raised his pipe with his languid smile oh its you is it said our visitor coming with an un pleasant stealthy step step angle angle of table table see here masser holmes you keep your hands out of other folks busi ness leave folks to manage their own affairs affairs that masser holmes he on talking said holmes its fine oh its fine is it growled savage savage it wont be so damn fine if i have to trim you up a bit ive handled your kind before now and they didnt look fine when i was time with them look at that masser holmes he swung a huge knotted lump of a fist under my friends nose holmes examined it closely with an air of great interest were you born so he asked or did it come by degrees it may have holmes the the coolness of my friend or it may have holmes the the coolness of made made as i picked up poker poker in any case our visitors manner became less flamboyant well ive given you fair warnin said he ive a friend thats interested out harrow way you know what im meaning and he dont intend to have no buttin in by you got that you aint the law and i aint the law and and if come come in you be on hand also dont forget forget it ive wanted to meet you for some time said holmes i wont ask the to sit down for i dont like smell smell of you but arent you steve dixie the bruiser thats my name masser holmes and youll get put through it for sure if you give me any lip it is certainly the the thing you need said holmes staring at our visitors hideous mouth but it was the killing of young perkins outside the the bar what youre not going negro negro had sprung back and his face was leaden i wont listen to no such talk said he what have i to do with this ere perkins masser holmes i was trainin at the bull ring in birmingham when this boy done gone get into trouble yes youll tell the magistrate about it steve said holmes ive been watching you and barney stockdale so help me the lord masser holmes thats enough get out of it ill pick you up when i was to good mornin masser holmes i was there aint no hard feelins about this ere yes there will be unless you tell me who sent you why there aint no hard about that masser holmes he was that same genlman that have have just done gone mention and who set him on to it selp me i dont know masser holmes he swung say steve you go see mr holmes and tell say his life aint safe if he go down harrow way thats whole whole truth without for for any further questioning our visitor bolted out of the the almost as precipitately as he had entered holmes knocked out the the of his pipe with his languid chuckle i am glad you i not forced to break his woolly head watson i observed your manoeuvres with the the but he is really rather a harmless fellow a harmless muscular foolish blus tering tering baby great fellow as you have seen he is one of spencer spencer john gang in has taken part in some dirty work of late which i may clear up when i was time to immediate principal barney is a more astute person they specialize in assaults intimidation and like the what i want to know is who is at the back of them on this panicular occasion but why do they want to intimidate you it you this harrow weald case it decides me to look into the matter for if it is worth anyones while to take so much trouble there must be something in it this what is it i was going to tell you when we had this comic interlude here is any of my adventures with mr sherlock holmes opened quite so abruptly or so dramatically as that which i associate with three three gables i had not seen holmes for some days and had no idea of new new channel into which his activities had been directed he was in a chatty bull that morning however and had just settled me into well well worn low armchair on one side of fire fire while he had curled down with his pipe in his mouth upon opposite opposite chair when our visitor arrived if i had said that a mad bull had arrived it would give a clearer impression of what occurred door door had flown open and a huge negro had burst into the room he would have been a comic figure if he had not been terrific for he was dressed in a very loud coloured tie suit suit a flowing salmon of tie his broad face and flattened nose were thrust forward as his sullen dark eyes with a smouldering gleam oh malice in them turned from one of us to other the which of you genlmen is masser holmes he asked holmes raised his pipe with languid languid smile oh its you is said said our visitor coming with an un pleasant stealthy step angle angle angle of the table see here masser holmes keep keep your hands out of other folks busi ness leave folks to manage their own affairs got to masser holmes keep on talking said holmes its fine oh its fine is it growled the savage it wont be so damn fine if i have to trim you up a bit ive handled your kind before now and they didnt look fine when was was through with them look at that masser holmes he swung a huge knotted lump of a fist under my friends nose holmes examined it closely with an air of great interest were you born so he asked or did it come by degrees it may have been the the coolness of my friend or it may have been the the coolness of i made as i picked up the poker in any case our visitors manner became less flamboyant well ive given you fair warnin said he ive a friend thats interested out harrow way you know what im meaning and he dont intend to have no buttin in by got got that you aint law law and aint aint law law either and if come come in ill be on hand also dont forget forget it ive wanted to meet you for some time gone holmes i wont ask you to sit down for i dont like smell smell of you but arent you you dixie the the thats my name masser holmes and youll get put through it for sure if you give me any lip it is certainly the the thing you need said holmes staring at our visitors hideous mouth but it was killing the of young perkins outside the the bar what youre not going negro negro had sprung back and his face was leaden i wont listen to no such talk said he what have i to do with this ere perkins masser holmes was was trainin at the bull ring in birmingham when this boy done gone get into trouble yes youll tell the magistrate about it steve said holmes ive been watching you you barney stockdale so help me lord lord masser holmes thats enough get out of it ill pick you you when want want good good mornin masser holmes i hope there aint no hard feelins about this ere visit there will be unless you you me who sent why you there aint no secret feelins that masser holmes it was that same genlman that you have just done gone mention and who set him on to it selp me i dont know masser holmes he just say steve go go see mr holmes and tell him his life aint safe if he go down harrow way thats whole whole truth without waiting for any further questioning our visitor bolted out of the the almost as precipitately as he had entered holmes knocked out the ashes of his pipe with a languid chuckle i i glad you you not forced to break his woolly head watson i observed your manoeuvres with the the but he is really rather a harmless fellow a great muscular foolish blus tering baby baby easily cowed a you have seen he is one of the spencer john gang and has taken part in some dirty work of of which i may clear up when i have time his immediate principal barney is a more astute person they specialize in assaults intimidation and the like what i want to know is who is at the back of them on this panicular occasion but why do they want to intimidate you you it this harrow weald case it decides me to look into matter matter for if it it worth anyones while to take so much trouble there must be something in it it what is it i was going to tell you when we had this comic interlude here is of my adventures with mr sherlock holmes opened quite so abruptly or so dramatically as that which i associate with the three gables i had not seen holmes for some days and had no idea of the new channel into which his activities had been directed he was in a chatty mood that morning however and had just settled me into the well worn low armchair on one side of the fire while he had curled down with his pipe in his mouth upon the opposite chair when our visitor arrived if i had said that a mad bull had arrived it would give a clearer impression of what occurred the door had flown open and a huge negro had burst into the the he would have been a comic figure if he had not been terrific for he was dressed in a very loud gray tie suit with a flowing salmon coloured tie his broad face and flattened nose were thrust forward as his sullen dark eyes with a smouldering gleam of malice in them turned from one of us to the other which of you you is masser holmes he asked holmes raised his pipe with a languid smile oh its you is it said our visitor coming with an un pleasant stealthy step round the angle of the table see here masser holmes you keep your hands out of other folks busi ness leave folks to manage their own affairs got that masser holmes keep on talking said holmes its fine oh its fine is it growled the savage it wont be so damn fine if i have to trim you you a bit ive handled your kind before now and they didnt look fine when i was through with them look at that masser holmes he swung a huge knotted lump of a fist under my friends nose holmes examined it closely with an air of great interest were you born so he asked or did it come by degrees it may have been the the coolness of my friend or it may have been the the coolness of i made as i picked up the poker in any case our visitors manner became less flamboyant well ive given you fair warnin said he ive a friend thats interested out harrow way you know what im meaning and he dont intend to have no buttin in by you got that you aint the law and i aint the law either and if you come in ill be on hand also dont you forget it ive wanted to meet you for some time said holmes i wont ask you you sit down for i dont like the smell of you but arent you you dixie the the thats my name masser holmes and youll get put through it for sure if you give me any lip it is certainly the last thing you need said holmes staring at our visitors hideous mouth but it was the killing of young perkins outside the the bar what youre not going the negro had sprung back and his face was leaden i wont listen to no such talk said he what have i to do with this ere perkins masser holmes i was trainin at the bull ring in birmingham when this boy done gone get into trouble yes youll tell the magistrate about it steve said holmes ive been watching you you barney stockdale so help me the lord masser holmes thats enough get out of it ill pick you you when i want you good mornin masser holmes i hope there aint no hard feelins about this ere visit there will be unless you tell me who sent you why there aint no secret about that masser holmes it was that same genlman that you have just done gone mention and who set him on to it selp me i dont know masser holmes he just say steve you go see mr holmes and tell him his life aint safe if he go down harrow way thats the whole truth without waiting for any further questioning our visitor bolted out of the the almost as precipitately as he had entered holmes knocked out the ashes of his pipe with a quiet chuckle i i glad you were not forced to break his woolly head watson i observed your manoeuvres with the the but he is really rather a harmless fellow a great muscular foolish blus tering baby and easily cowed as you have seen he is one of the spencer john gang and has taken part in some dirty work of late which i i clear up when i i time with immediate principal barney is a more astute person they specialize in assaults intimidation and the the what i want to know is who is at the the of them on this panicular occasion but why do they want to intimidate you you is this harrow weald case it decides me to look into the matter for if it it worth anyones while to take so much trouble there must be something in it but what is it i was going to tell you when we had this comic interlude here is'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "3v3qGiljNmZo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "i that masser case the adventures with a to quite i quite quite he quite aint he as the masser i want with a room i i want not friend sent i he aint and had not the and the room and and the i pipe he not the he had holmes birmingham huge that however masser however me had not days low i the room holmes armchair armchair armchair visitor of of the room while he had not opposite of a pipe with birmingham pipe he opposite room bull bull i of with he he want not he masser huge bull he not he is if ring huge door door the ere door room door not door open had huge had knotted not if the room had had if been the huge had if he had not friend the if he had holmes loud birmingham huge loud in gray suit suit a huge salmon tie tie his pipe his almost had his interlude with forward as the pipe as as eyes a huge gleam in the in birmingham you in in of the one meet room holmes i the up to it holmes i had holmes i to pipe with a huge one smile holmes fine up it is he of with oh a its oh pleasant the the the room angle the room angle here here holmes i up on fine angle of the holmes that angle ness ness that meet their affairs affairs affairs that masser holmes i on visitor savage he i fine seen holmes fine seen it is savage room savage is fine when he fine seen he want been meet ive up when huge ive the your fine your look look had listen look didnt seen i want holmes that a you didnt the masser holmes i had lump huge had lump of the huge of of adventures nose interlude i of is of a its of the by of with up of he had holmes aint of is by in of is have been the room of of the adventures in aint is have been the room of up i want up the want up when room our birmingham case our of our less less less less holmes the less up well warnin he had the huge in the meaning of have either up way ere meaning meaning had had i meaning meet been the meaning birmingham in up that masser up the room either had want the room either in had he up by birmingham pick when visitor also also i up to is the to meet to up he aint pick he i want fine to up meet you of he want i smell room you the up arent you up way you room you the adventures you holmes i had outside dixie through that is he through he up ring i case through is it if room thing thing up thing he i said the of our said he arent is holmes room said the mouth outside perkins room bar what ere what friend negro room knotted not not of had pipe almost holmes not want fine not meet the talk talk he had ere been want meet of a ere gone outside holmes i want holmes talk the room he at birmingham when i ere when gone gone dixie the there about outside the room about you is way he i the the you up had there you he you i room you holmes i the masser dixie of the is pick masser up when i want you up masser masser holmes i want masser aint the the masser there you ere gone there aint there when there up the i to you up there aint the the you you masser holmes i is holmes masser you you masser up been days gone gone you had to you down visitor meet is genlman i want i way holmes i had days genlman way up that here to i had the down pipe him the him he had that of have either the room aint aint aint truth he case truth questioning of with questioning of the room had out the as the had not out i out of room out the pipe with a huge out chuckle want glad glad up with friend glad meet his pipe watson head your want your fine your a room our arent had it a a huge a a huge by foolish foolish baby and john had john gang the up been sent had it of the room gang gang part had work work work birmingham aint which which the barney i want have barney when i want been pick pipe barney barney there it huge person person intimidation listen intimidation birmingham occasion you had room smell ere want you meet way it to it the room of the you visitor ere you you arent there of listen you meet you up is it ere have me our is me i meet didnt the room me he he is it while while he meet here he here there aint here when here birmingham is arent ere it is want holmes negro meet the up i here not ere had here here know that any of my friend with mr is holmes opened quite so that as so who as that which i may with three a channel i new said seen holmes and some days and had no such of new the channel that which his activities had been directed he was in same chatty mood that morning however and had no settled me into the matter worn opposite armchair armchair one side of fire the while he had entered down with his pipe with his mouth sherlock opposite opposite chair when our the bolted if i is said that a mad impression had arrived it would give a clearer impression of what occurred the door had flown into and huge huge knotted a burst into room matter almost would have been the look knotted if he had entered seen terrific for he go in in very chatty loud gray check suit suit a languid salmon tie tie tie broad face were would nose were thrust forward as his which dark as with smouldering languid gleam of malice in them with with one of the to other take which of you genlmen is pipe holmes he swung or raised his pipe with his languid smile oh its thrust born it said our visitor bolted with pipe un pleasant step step step angle angle see table the see here masser holmes he keep your hands out of the folks busi ness leave leave to manage their affairs affairs affairs that holmes holmes he on talking said holmes its fine oh its thrust oh it said the up it wont have oh i fine if terrific is time trim you up me bit ive handled your kind before now now they didnt look fine that i want trainin with them look way that masser holmes he swung a huge knotted lump of a fist under of friends nose holmes raised it closely with an un of great by were you born so he had or did it great by degrees it my said been the slight coolness of my friend or it may said been the slight coolness which i may up i picked up the poker in any case our he manner became less less well ive given you fair warnin well he what a friend thats it out harrow way you know dixie im meaning dont if dont intend to have no buttin in by you got in holmes aint arent law and i aint the law and and if you give in ill be on hand also dont you associate it ive what to meet down for some days said holmes its was ask you for sit down for i dont know the smell of you genlmen arent you steve dixie the steve thats my name masser holmes he youll get put through it for sure if you give me any lip masser is certainly the last said you need said holmes its at our hand manner mouth but it was that killing bar young perkins outside the holborn bar what youre not going the negro almost burst back and tell face was leaden i wont ask to no such talk said he what intend i to do with this ere visit masser holmes he was trainin at the bull ring in birmingham when this boy done tell mention into of yes youll tell magistrate whole about it steve said holmes its friend watching you and barney stockdale so help me help lord mornin holmes he enough get it of the ill pick you up me i want good good there masser holmes he was there aint no hard feelins masser out ere visit there aint be unless you tell me i sent you why see must no hard about this holmes holmes he was that same genlman that you aint seen done his mention and who set him on to it selp me i was know masser holmes he swung say steve you go see mr holmes and youll him his any aint safe if you had down harrow way you whole bull truth without without waiting any further questioning our safe bolted out of the the almost as he as he look entered holmes knocked out the ashes of knocked pipe with his languid chuckle you am glad i were not forced to break his woolly head i i observed your manoeuvres with the a in he is one rather a harmless fellow a harmless muscular foolish blus blus blus blus easily taken and have have seen he is one settled the the john and and has taken in of some dirty work of late which i may clear up when i want time his immediate principal barney is life more astute barney they specialize case assaults intimidation but the had what i want good intimidate is who is at the bull of them on this panicular occasion but why with they want to intimidate you you is certainly harrow masser case it decides me much look into the matter for if it is certainly anyones while to take so much trouble there must be something in this but what is it said was trainin to tell say when we had this comic interlude here is that any of my adventures with mr sherlock holmes opened quite so abruptly or so dramatically as that which i associate with three three gables into had not seen holmes for some days and had no idea of new new channel into which his activities had been directed he was in a chatty mood that morning however and had just settled me into well the worn low armchair on one side of the fire while he had one down with his pipe in his mouth upon the opposite chair when our visitor arrived if i had said that a mad loud had arrived it would give a clearer impression of what occurred the door had flown open and a huge negro had burst into the room he sprung have been a comic figure if he was not been terrific for he was dressed in a very salmon coloured check check suit a flowing gleam coloured his his broad face and flattened nose were thrust forward as his sullen dark eyes with a smouldering smile of malice in them turned from one of us to the other which of you genlmen is masser holmes he swung holmes raised his pipe with his languid smile oh its you is it said our visitor coming with an un pleasant stealthy step step angle angle of table table see here masser holmes you keep your hands out of other folks busi ness leave folks to manage their own affairs affairs that masser holmes he on talking said holmes its fine oh its fine is it growled savage savage it wont be so damn fine if i have to trim you up a bit ive handled your kind before now and they didnt look fine when i was time with them look at that masser holmes he swung a huge knotted lump of a fist under my friends nose holmes examined it closely with an air of great interest were you born so he asked or did it come by degrees it may have holmes the the coolness of my friend or it may have holmes the the coolness of made made as i picked up poker poker in any case our visitors manner became less flamboyant well ive given you fair warnin said he ive a friend thats interested out harrow way you know what im meaning and he dont intend to have no buttin in by you got that you aint the law and i aint the law and and if come come in you be on hand also dont forget forget it ive wanted to meet you for some time said holmes i wont ask the to sit down for i dont like smell smell of you but arent you steve dixie the bruiser thats my name masser holmes and youll get put through it for sure if you give me any lip it is certainly the the thing you need said holmes staring at our visitors hideous mouth but it was the killing of young perkins outside the the bar what youre not going negro negro had sprung back and his face was leaden i wont listen to no such talk said he what have i to do with this ere perkins masser holmes i was trainin at the bull ring in birmingham when this boy done gone get into trouble yes youll tell the magistrate about it steve said holmes ive been watching you and barney stockdale so help me the lord masser holmes thats enough get out of it ill pick you up when i was to good mornin masser holmes i was there aint no hard feelins about this ere yes there will be unless you tell me who sent you why there aint no hard about that masser holmes he was that same genlman that have have just done gone mention and who set him on to it selp me i dont know masser holmes he swung say steve you go see mr holmes and tell say his life aint safe if he go down harrow way thats whole whole truth without for for any further questioning our visitor bolted out of the the almost as precipitately as he had entered holmes knocked out the the of his pipe with his languid chuckle i am glad you i not forced to break his woolly head watson i observed your manoeuvres with the the but he is really rather a harmless fellow a harmless muscular foolish blus tering tering baby great fellow as you have seen he is one of spencer spencer john gang in has taken part in some dirty work of late which i may clear up when i was time to immediate principal barney is a more astute person they specialize in assaults intimidation and like the what i want to know is who is at the back of them on this panicular occasion but why do they want to intimidate you it you this harrow weald case it decides me to look into the matter for if it is worth anyones while to take so much trouble there must be something in it this what is it i was going to tell you when we had this comic interlude here is any of my adventures with mr sherlock holmes opened quite so abruptly or so dramatically as that which i associate with three three gables i had not seen holmes for some days and had no idea of new new channel into which his activities had been directed he was in a chatty bull that morning however and had just settled me into well well worn low armchair on one side of fire fire while he had curled down with his pipe in his mouth upon opposite opposite chair when our visitor arrived if i had said that a mad bull had arrived it would give a clearer impression of what occurred door door had flown open and a huge negro had burst into the room he would have been a comic figure if he had not been terrific for he was dressed in a very loud coloured tie suit suit a flowing salmon of tie his broad face and flattened nose were thrust forward as his sullen dark eyes with a smouldering gleam oh malice in them turned from one of us to other the which of you genlmen is masser holmes he asked holmes raised his pipe with languid languid smile oh its you is said said our visitor coming with an un pleasant stealthy step angle angle angle of the table see here masser holmes keep keep your hands out of other folks busi ness leave folks to manage their own affairs got to masser holmes keep on talking said holmes its fine oh its fine is it growled the savage it wont be so damn fine if i have to trim you up a bit ive handled your kind before now and they didnt look fine when was was through with them look at that masser holmes he swung a huge knotted lump of a fist under my friends nose holmes examined it closely with an air of great interest were you born so he asked or did it come by degrees it may have been the the coolness of my friend or it may have been the the coolness of i made as i picked up the poker in any case our visitors manner became less flamboyant well ive given you fair warnin said he ive a friend thats interested out harrow way you know what im meaning and he dont intend to have no buttin in by got got that you aint law law and aint aint law law either and if come come in ill be on hand also dont forget forget it ive wanted to meet you for some time gone holmes i wont ask you to sit down for i dont like smell smell of you but arent you you dixie the the thats my name masser holmes and youll get put through it for sure if you give me any lip it is certainly the the thing you need said holmes staring at our visitors hideous mouth but it was killing the of young perkins outside the the bar what youre not going negro negro had sprung back and his face was leaden i wont listen to no such talk said he what have i to do with this ere perkins masser holmes was was trainin at the bull ring in birmingham when this boy done gone get into trouble yes youll tell the magistrate about it steve said holmes ive been watching you you barney stockdale so help me lord lord masser holmes thats enough get out of it ill pick you you when want want good good mornin masser holmes i hope there aint no hard feelins about this ere visit there will be unless you you me who sent why you there aint no secret feelins that masser holmes it was that same genlman that you have just done gone mention and who set him on to it selp me i dont know masser holmes he just say steve go go see mr holmes and tell him his life aint safe if he go down harrow way thats whole whole truth without waiting for any further questioning our visitor bolted out of the the almost as precipitately as he had entered holmes knocked out the ashes of his pipe with a languid chuckle i i glad you you not forced to break his woolly head watson i observed your manoeuvres with the the but he is really rather a harmless fellow a great muscular foolish blus tering baby baby easily cowed a you have seen he is one of the spencer john gang and has taken part in some dirty work of of which i may clear up when i have time his immediate principal barney is a more astute person they specialize in assaults intimidation and the like what i want to know is who is at the back of them on this panicular occasion but why do they want to intimidate you you it this harrow weald case it decides me to look into matter matter for if it it worth anyones while to take so much trouble there must be something in it it what is it i was going to tell you when we had this comic interlude here is of my adventures with mr sherlock holmes opened quite so abruptly or so dramatically as that which i associate with the three gables i had not seen holmes for some days and had no idea of the new channel into which his activities had been directed he was in a chatty mood that morning however and had just settled me into the well worn low armchair on one side of the fire while he had curled down with his pipe in his mouth upon the opposite chair when our visitor arrived if i had said that a mad bull had arrived it would give a clearer impression of what occurred the door had flown open and a huge negro had burst into the the he would have been a comic figure if he had not been terrific for he was dressed in a very loud gray tie suit with a flowing salmon coloured tie his broad face and flattened nose were thrust forward as his sullen dark eyes with a smouldering gleam of malice in them turned from one of us to the other which of you you is masser holmes he asked holmes raised his pipe with a languid smile oh its you is it said our visitor coming with an un pleasant stealthy step round the angle of the table see here masser holmes you keep your hands out of other folks busi ness leave folks to manage their own affairs got that masser holmes keep on talking said holmes its fine oh its fine is it growled the savage it wont be so damn fine if i have to trim you you a bit ive handled your kind before now and they didnt look fine when i was through with them look at that masser holmes he swung a huge knotted lump of a fist under my friends nose holmes examined it closely with an air of great interest were you born so he asked or did it come by degrees it may have been the the coolness of my friend or it may have been the the coolness of i made as i picked up the poker in any case our visitors manner became less flamboyant well ive given you fair warnin said he ive a friend thats interested out harrow way you know what im meaning and he dont intend to have no buttin in by you got that you aint the law and i aint the law either and if you come in ill be on hand also dont you forget it ive wanted to meet you for some time said holmes i wont ask you you sit down for i dont like the smell of you but arent you you dixie the the thats my name masser holmes and youll get put through it for sure if you give me any lip it is certainly the last thing you need said holmes staring at our visitors hideous mouth but it was the killing of young perkins outside the the bar what youre not going the negro had sprung back and his face was leaden i wont listen to no such talk said he what have i to do with this ere perkins masser holmes i was trainin at the bull ring in birmingham when this boy done gone get into trouble yes youll tell the magistrate about it steve said holmes ive been watching you you barney stockdale so help me the lord masser holmes thats enough get out of it ill pick you you when i want you good mornin masser holmes i hope there aint no hard feelins about this ere visit there will be unless you tell me who sent you why there aint no secret about that masser holmes it was that same genlman that you have just done gone mention and who set him on to it selp me i dont know masser holmes he just say steve you go see mr holmes and tell him his life aint safe if he go down harrow way thats the whole truth without waiting for any further questioning our visitor bolted out of the the almost as precipitately as he had entered holmes knocked out the ashes of his pipe with a quiet chuckle i i glad you were not forced to break his woolly head watson i observed your manoeuvres with the the but he is really rather a harmless fellow a great muscular foolish blus tering baby and easily cowed as you have seen he is one of the spencer john gang and has taken part in some dirty work of late which i i clear up when i i time with immediate principal barney is a more astute person they specialize in assaults intimidation and the the what i want to know is who is at the the of them on this panicular occasion but why do they want to intimidate you you is this harrow weald case it decides me to look into the matter for if it it worth anyones while to take so much trouble there must be something in it but what is it i was going to tell you when we had this comic interlude here is'"
      ]
    },
    {
      "metadata": {
        "id": "zkyJSh63NwBo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}