{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Writing_with_sentence-word_prediction-tpu.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nik8x/Deep_writing_generating_text/blob/master/Deep_Writing_with_sentence_word_prediction_lstm_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "vUb856aHtNq_",
        "colab_type": "code",
        "outputId": "d7b8044a-8484-469d-b56d-f21f24318dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import regex as re\n",
        "\n",
        "import nltk\n",
        "from nltk.draw.dispersion import dispersion_plot\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.probability import FreqDist\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.util import ngrams\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import urllib\n",
        "\n",
        "import os\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "f3MnaG43tZeA",
        "colab_type": "code",
        "outputId": "7c884320-232a-4737-8b0c-65a61bed712a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "text = urllib.request.urlopen('http://www.textfiles.com/stories/3gables.txt').read().decode('utf8')\n",
        "text = text.replace('\\n', ' ').replace('\\r', '').replace(\"\\'\", \"\").replace('\\w+', '')[348:500]\n",
        "text[0:1000]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'   I dont think that any of my adventures with Mr. Sherlock Holmes opened quite so abruptly, or so dramatically, as that which I associate with The Thre'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "mS16E8LAtfBA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# I will first convert all the words to numbers, then normalize them, then make a dataframe with two columns, \n",
        "# one with sentences(one word, then two words, and so on), the other with the exact next word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnHkDWF6uB-7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# integer encode text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "encoded = tokenizer.texts_to_sequences([text])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntGz5c9lukSF",
        "colab_type": "code",
        "outputId": "8fa4e794-9b25-4cd8-951f-d4e24ae50b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# determine the vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size: %d' % vocab_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "olhiAHoo5Q26",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x = pd.DataFrame(pd.Series([encoded[:i] for i in range(len(encoded))]))\n",
        "# x['label'] = pd.DataFrame([i for i in encoded])\n",
        "# x.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aa77eQj05bpI",
        "colab_type": "code",
        "outputId": "676aa0b2-8fc3-4579-b3e1-8cd0b426519f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "listy = []\n",
        "\n",
        "for i in range(len(encoded)):\n",
        "  listy.append(encoded[:i])\n",
        "  \n",
        "len(listy)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "gO15yM1vdofW",
        "colab_type": "code",
        "outputId": "a939c914-285b-43a4-9e60-901d7f6c1b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "cell_type": "code",
      "source": [
        "listy[1:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1],\n",
              " [1, 5],\n",
              " [1, 5, 6],\n",
              " [1, 5, 6, 2],\n",
              " [1, 5, 6, 2, 7],\n",
              " [1, 5, 6, 2, 7, 8],\n",
              " [1, 5, 6, 2, 7, 8, 9],\n",
              " [1, 5, 6, 2, 7, 8, 9, 10],\n",
              " [1, 5, 6, 2, 7, 8, 9, 10, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "UHAmZBhhYFzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# np.array([np.array(xi) for xi in listy[1:]]) # creating array retaining the shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LH0pUQEJZuNw",
        "colab_type": "code",
        "outputId": "72c4417c-4cb4-4265-e80d-7605d0ed97b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "length = len(sorted(listy[1:],key = len, reverse = True)[0])   # creating array by adding 0 to make all rows equal\n",
        "X = np.array([xi + [0] * (length - len(xi)) for xi in listy[1:]])\n",
        "X.shape  # creating X array"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "YOpL0qlCsVff",
        "colab_type": "code",
        "outputId": "c1b67b25-80a5-42a2-d486-bb253b6e0743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
            "  warnings.warn(msg, DataConversionWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EaIZP8UtX0J9",
        "colab_type": "code",
        "outputId": "4af27a60-ae39-4b8a-d540-dda30f0238d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.        , -5.        , -3.46410162, -2.76887462, -2.34520788,\n",
              "       -2.04939015, -1.82574186, -1.64750894, -1.5       , -1.37436854,\n",
              "       -1.26491106, -1.16774842, -1.08012345, -1.        , -0.9258201 ,\n",
              "       -0.85634884, -0.79056942, -0.72760688, -0.66666667, -0.60697698,\n",
              "       -0.54772256, -0.48795004, -0.42640143, -0.36115756, -0.28867513,\n",
              "       -0.2       ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "bMq9FIMbN7tq",
        "colab_type": "code",
        "outputId": "22cbd840-36a1-44a9-f118-bb686b0a6232",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "y = [i for i in encoded][1:] # creating y array\n",
        "len(y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "kBtV_MblN_ly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# one hot encode outputs\n",
        "y = to_categorical(y, num_classes = vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M8hS0EsOsHZK",
        "colab_type": "code",
        "outputId": "fd522677-25a1-45fc-a770-6a449b6e6ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "fh72jiM3LZkH",
        "colab_type": "code",
        "outputId": "d4f9d6be-4605-42b4-95b1-6e3c0a67814a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26, 26), (26, 24))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "lT6XGFybeuRM",
        "colab_type": "code",
        "outputId": "7a6e0e7a-a0c3-4fca-f38a-e6854d2370ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# LSTMs accept input in the form of (number_of_sequences, length_of_sequence, number_of_features)\n",
        "X_lstm = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "X_lstm.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 26, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "AiS7DGsZfg4A",
        "colab_type": "code",
        "outputId": "9fd53ede-f381-416a-df27-1c2284cf7c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(50, input_shape = (X_lstm.shape[1], X_lstm.shape[2])))#, return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(50, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(2500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(50))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                1224      \n",
            "=================================================================\n",
            "Total params: 11,624\n",
            "Trainable params: 11,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XDd_BheDe5jb",
        "colab_type": "code",
        "outputId": "d6bea933-116e-4a5e-960c-fa2fe14f515f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "cell_type": "code",
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.94.156.26:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3566480658991856900)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17212933578758057838)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 13481736650929986321)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 768218785289235016)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2522603521490514475)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13108019931984311059)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 13779723367914735299)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9962943762118349744)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13019648169068274998)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 12687249396682232144)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2335844898909077989)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "54bVMlFbfAJU",
        "colab_type": "code",
        "outputId": "859a139b-74e0-4d76-f8c5-b134307ce73a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_input (InputLayer)      (None, 26, 1)             0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50)                10400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                1224      \n",
            "=================================================================\n",
            "Total params: 11,624\n",
            "Trainable params: 11,624\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HnaZY1IrfEso",
        "colab_type": "code",
        "outputId": "497fb6f2-14a4-4929-b598-f1f988a9abd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18188
        }
      },
      "cell_type": "code",
      "source": [
        "#early_stopping_monitor = EarlyStopping(monitor = 'loss', patience = 4, verbose = 0, mode='auto')\n",
        "tpu_model.fit(X_lstm, y, epochs = 500, batch_size = 50)#, callbacks = [early_stopping_monitor])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(3,), dtype=tf.int32, name='core_id0'), TensorSpec(shape=(3, 26, 1), dtype=tf.float32, name='lstm_input_10'), TensorSpec(shape=(3, 24), dtype=tf.float32, name='dense_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for lstm_input\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py:302: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f94db0d3940> []\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 2.1261789798736572 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.0010000000474974513 {0.001}\n",
            "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "26/26 [==============================] - 10s 402ms/sample - loss: 3.1914 - acc: 0.0417\n",
            "Epoch 2/500\n",
            "26/26 [==============================] - 0s 597us/sample - loss: 3.2051 - acc: 0.0417\n",
            "Epoch 3/500\n",
            "26/26 [==============================] - 0s 598us/sample - loss: 3.1742 - acc: 0.0417\n",
            "Epoch 4/500\n",
            "26/26 [==============================] - 0s 479us/sample - loss: 3.1832 - acc: 0.0000e+00\n",
            "Epoch 5/500\n",
            "26/26 [==============================] - 0s 568us/sample - loss: 3.1624 - acc: 0.0417\n",
            "Epoch 6/500\n",
            "26/26 [==============================] - 0s 497us/sample - loss: 3.1645 - acc: 0.0417\n",
            "Epoch 7/500\n",
            "26/26 [==============================] - 0s 490us/sample - loss: 3.1555 - acc: 0.1250\n",
            "Epoch 8/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 3.1553 - acc: 0.0833\n",
            "Epoch 9/500\n",
            "26/26 [==============================] - 0s 487us/sample - loss: 3.1351 - acc: 0.0417\n",
            "Epoch 10/500\n",
            "26/26 [==============================] - 0s 522us/sample - loss: 3.1313 - acc: 0.0833\n",
            "Epoch 11/500\n",
            "26/26 [==============================] - 0s 470us/sample - loss: 3.1269 - acc: 0.0417\n",
            "Epoch 12/500\n",
            "26/26 [==============================] - 0s 521us/sample - loss: 3.1459 - acc: 0.0000e+00\n",
            "Epoch 13/500\n",
            "26/26 [==============================] - 0s 538us/sample - loss: 3.1234 - acc: 0.0833\n",
            "Epoch 14/500\n",
            "26/26 [==============================] - 0s 611us/sample - loss: 3.1227 - acc: 0.0417\n",
            "Epoch 15/500\n",
            "26/26 [==============================] - 0s 459us/sample - loss: 3.0985 - acc: 0.0833\n",
            "Epoch 16/500\n",
            "26/26 [==============================] - 0s 474us/sample - loss: 3.0924 - acc: 0.0417\n",
            "Epoch 17/500\n",
            "26/26 [==============================] - 0s 532us/sample - loss: 3.0799 - acc: 0.0833\n",
            "Epoch 18/500\n",
            "26/26 [==============================] - 0s 462us/sample - loss: 3.0869 - acc: 0.0833\n",
            "Epoch 19/500\n",
            "26/26 [==============================] - 0s 465us/sample - loss: 3.0773 - acc: 0.0833\n",
            "Epoch 20/500\n",
            "26/26 [==============================] - 0s 467us/sample - loss: 3.0483 - acc: 0.1250\n",
            "Epoch 21/500\n",
            "26/26 [==============================] - 0s 462us/sample - loss: 3.0439 - acc: 0.0833\n",
            "Epoch 22/500\n",
            "26/26 [==============================] - 0s 514us/sample - loss: 3.0359 - acc: 0.0417\n",
            "Epoch 23/500\n",
            "26/26 [==============================] - 0s 804us/sample - loss: 3.0392 - acc: 0.0833\n",
            "Epoch 24/500\n",
            "26/26 [==============================] - 0s 497us/sample - loss: 3.0169 - acc: 0.0417\n",
            "Epoch 25/500\n",
            "26/26 [==============================] - 0s 500us/sample - loss: 3.0193 - acc: 0.0417\n",
            "Epoch 26/500\n",
            "26/26 [==============================] - 0s 436us/sample - loss: 2.9838 - acc: 0.0833\n",
            "Epoch 27/500\n",
            "26/26 [==============================] - 0s 465us/sample - loss: 2.9817 - acc: 0.0833\n",
            "Epoch 28/500\n",
            "26/26 [==============================] - 0s 581us/sample - loss: 2.9655 - acc: 0.0833\n",
            "Epoch 29/500\n",
            "26/26 [==============================] - 0s 454us/sample - loss: 2.9800 - acc: 0.1250\n",
            "Epoch 30/500\n",
            "26/26 [==============================] - 0s 527us/sample - loss: 2.9268 - acc: 0.1250\n",
            "Epoch 31/500\n",
            "26/26 [==============================] - 0s 488us/sample - loss: 2.8697 - acc: 0.1250\n",
            "Epoch 32/500\n",
            "26/26 [==============================] - 0s 640us/sample - loss: 2.9020 - acc: 0.0833\n",
            "Epoch 33/500\n",
            "26/26 [==============================] - 0s 510us/sample - loss: 2.9246 - acc: 0.0417\n",
            "Epoch 34/500\n",
            "26/26 [==============================] - 0s 642us/sample - loss: 2.8525 - acc: 0.0833\n",
            "Epoch 35/500\n",
            "26/26 [==============================] - 0s 493us/sample - loss: 2.9207 - acc: 0.0833\n",
            "Epoch 36/500\n",
            "26/26 [==============================] - 0s 471us/sample - loss: 2.8662 - acc: 0.0833\n",
            "Epoch 37/500\n",
            "26/26 [==============================] - 0s 539us/sample - loss: 2.8319 - acc: 0.1250\n",
            "Epoch 38/500\n",
            "26/26 [==============================] - 0s 564us/sample - loss: 2.8927 - acc: 0.0417\n",
            "Epoch 39/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 2.7613 - acc: 0.1250\n",
            "Epoch 40/500\n",
            "26/26 [==============================] - 0s 477us/sample - loss: 2.8386 - acc: 0.0417\n",
            "Epoch 41/500\n",
            "26/26 [==============================] - 0s 580us/sample - loss: 2.7733 - acc: 0.1250\n",
            "Epoch 42/500\n",
            "26/26 [==============================] - 0s 497us/sample - loss: 2.7379 - acc: 0.1250\n",
            "Epoch 43/500\n",
            "26/26 [==============================] - 0s 517us/sample - loss: 2.7476 - acc: 0.1250\n",
            "Epoch 44/500\n",
            "26/26 [==============================] - 0s 528us/sample - loss: 2.7516 - acc: 0.0833\n",
            "Epoch 45/500\n",
            "26/26 [==============================] - 0s 477us/sample - loss: 2.6711 - acc: 0.2083\n",
            "Epoch 46/500\n",
            "26/26 [==============================] - 0s 455us/sample - loss: 2.6924 - acc: 0.1250\n",
            "Epoch 47/500\n",
            "26/26 [==============================] - 0s 497us/sample - loss: 2.8027 - acc: 0.0833\n",
            "Epoch 48/500\n",
            "26/26 [==============================] - 0s 470us/sample - loss: 2.7766 - acc: 0.0833\n",
            "Epoch 49/500\n",
            "26/26 [==============================] - 0s 451us/sample - loss: 2.6747 - acc: 0.1667\n",
            "Epoch 50/500\n",
            "26/26 [==============================] - 0s 609us/sample - loss: 2.6454 - acc: 0.1667\n",
            "Epoch 51/500\n",
            "26/26 [==============================] - 0s 496us/sample - loss: 2.6839 - acc: 0.1250\n",
            "Epoch 52/500\n",
            "26/26 [==============================] - 0s 737us/sample - loss: 2.5702 - acc: 0.1667\n",
            "Epoch 53/500\n",
            "26/26 [==============================] - 0s 470us/sample - loss: 2.6575 - acc: 0.0833\n",
            "Epoch 54/500\n",
            "26/26 [==============================] - 0s 617us/sample - loss: 2.5706 - acc: 0.2083\n",
            "Epoch 55/500\n",
            "26/26 [==============================] - 0s 526us/sample - loss: 2.6489 - acc: 0.0417\n",
            "Epoch 56/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 2.5520 - acc: 0.1667\n",
            "Epoch 57/500\n",
            "26/26 [==============================] - 0s 514us/sample - loss: 2.5467 - acc: 0.1250\n",
            "Epoch 58/500\n",
            "26/26 [==============================] - 0s 653us/sample - loss: 2.5909 - acc: 0.1667\n",
            "Epoch 59/500\n",
            "26/26 [==============================] - 0s 628us/sample - loss: 2.4968 - acc: 0.2083\n",
            "Epoch 60/500\n",
            "26/26 [==============================] - 0s 570us/sample - loss: 2.4869 - acc: 0.3333\n",
            "Epoch 61/500\n",
            "26/26 [==============================] - 0s 566us/sample - loss: 2.5332 - acc: 0.1667\n",
            "Epoch 62/500\n",
            "26/26 [==============================] - 0s 634us/sample - loss: 2.4361 - acc: 0.2917\n",
            "Epoch 63/500\n",
            "26/26 [==============================] - 0s 519us/sample - loss: 2.4653 - acc: 0.2083\n",
            "Epoch 64/500\n",
            "26/26 [==============================] - 0s 463us/sample - loss: 2.5135 - acc: 0.1250\n",
            "Epoch 65/500\n",
            "26/26 [==============================] - 0s 488us/sample - loss: 2.4514 - acc: 0.2083\n",
            "Epoch 66/500\n",
            "26/26 [==============================] - 0s 554us/sample - loss: 2.4730 - acc: 0.2083\n",
            "Epoch 67/500\n",
            "26/26 [==============================] - 0s 491us/sample - loss: 2.4391 - acc: 0.2917\n",
            "Epoch 68/500\n",
            "26/26 [==============================] - 0s 534us/sample - loss: 2.2955 - acc: 0.2500\n",
            "Epoch 69/500\n",
            "26/26 [==============================] - 0s 510us/sample - loss: 2.4181 - acc: 0.2083\n",
            "Epoch 70/500\n",
            "26/26 [==============================] - 0s 695us/sample - loss: 2.3969 - acc: 0.1667\n",
            "Epoch 71/500\n",
            "26/26 [==============================] - 0s 568us/sample - loss: 2.2172 - acc: 0.2500\n",
            "Epoch 72/500\n",
            "26/26 [==============================] - 0s 527us/sample - loss: 2.2655 - acc: 0.2083\n",
            "Epoch 73/500\n",
            "26/26 [==============================] - 0s 441us/sample - loss: 2.2908 - acc: 0.2917\n",
            "Epoch 74/500\n",
            "26/26 [==============================] - 0s 542us/sample - loss: 2.2800 - acc: 0.2917\n",
            "Epoch 75/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 2.2552 - acc: 0.2917\n",
            "Epoch 76/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 2.2751 - acc: 0.2917\n",
            "Epoch 77/500\n",
            "26/26 [==============================] - 0s 527us/sample - loss: 2.3044 - acc: 0.2917\n",
            "Epoch 78/500\n",
            "26/26 [==============================] - 0s 458us/sample - loss: 2.2699 - acc: 0.2500\n",
            "Epoch 79/500\n",
            "26/26 [==============================] - 0s 549us/sample - loss: 2.1895 - acc: 0.2500\n",
            "Epoch 80/500\n",
            "26/26 [==============================] - 0s 484us/sample - loss: 2.1695 - acc: 0.4167\n",
            "Epoch 81/500\n",
            "26/26 [==============================] - 0s 523us/sample - loss: 2.2812 - acc: 0.2083\n",
            "Epoch 82/500\n",
            "26/26 [==============================] - 0s 511us/sample - loss: 2.0604 - acc: 0.3333\n",
            "Epoch 83/500\n",
            "26/26 [==============================] - 0s 515us/sample - loss: 2.2044 - acc: 0.2083\n",
            "Epoch 84/500\n",
            "26/26 [==============================] - 0s 481us/sample - loss: 2.2998 - acc: 0.2083\n",
            "Epoch 85/500\n",
            "26/26 [==============================] - 0s 470us/sample - loss: 2.0721 - acc: 0.3750\n",
            "Epoch 86/500\n",
            "26/26 [==============================] - 0s 488us/sample - loss: 2.1225 - acc: 0.2083\n",
            "Epoch 87/500\n",
            "26/26 [==============================] - 0s 541us/sample - loss: 2.2543 - acc: 0.1250\n",
            "Epoch 88/500\n",
            "26/26 [==============================] - 0s 474us/sample - loss: 2.1361 - acc: 0.2500\n",
            "Epoch 89/500\n",
            "26/26 [==============================] - 0s 504us/sample - loss: 2.0258 - acc: 0.4167\n",
            "Epoch 90/500\n",
            "26/26 [==============================] - 0s 552us/sample - loss: 2.0683 - acc: 0.2917\n",
            "Epoch 91/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 2.0581 - acc: 0.2917\n",
            "Epoch 92/500\n",
            "26/26 [==============================] - 0s 471us/sample - loss: 2.0915 - acc: 0.1667\n",
            "Epoch 93/500\n",
            "26/26 [==============================] - 0s 580us/sample - loss: 2.1346 - acc: 0.2917\n",
            "Epoch 94/500\n",
            "26/26 [==============================] - 0s 587us/sample - loss: 2.0938 - acc: 0.2083\n",
            "Epoch 95/500\n",
            "26/26 [==============================] - 0s 468us/sample - loss: 2.0907 - acc: 0.2083\n",
            "Epoch 96/500\n",
            "26/26 [==============================] - 0s 486us/sample - loss: 1.9480 - acc: 0.3333\n",
            "Epoch 97/500\n",
            "26/26 [==============================] - 0s 465us/sample - loss: 1.9892 - acc: 0.2500\n",
            "Epoch 98/500\n",
            "26/26 [==============================] - 0s 516us/sample - loss: 2.1237 - acc: 0.2083\n",
            "Epoch 99/500\n",
            "26/26 [==============================] - 0s 562us/sample - loss: 2.0802 - acc: 0.1667\n",
            "Epoch 100/500\n",
            "26/26 [==============================] - 0s 575us/sample - loss: 1.8830 - acc: 0.4583\n",
            "Epoch 101/500\n",
            "26/26 [==============================] - 0s 587us/sample - loss: 2.0001 - acc: 0.2083\n",
            "Epoch 102/500\n",
            "26/26 [==============================] - 0s 560us/sample - loss: 1.9609 - acc: 0.3333\n",
            "Epoch 103/500\n",
            "26/26 [==============================] - 0s 549us/sample - loss: 2.0050 - acc: 0.2917\n",
            "Epoch 104/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 1.9845 - acc: 0.3333\n",
            "Epoch 105/500\n",
            "26/26 [==============================] - 0s 588us/sample - loss: 1.8960 - acc: 0.4167\n",
            "Epoch 106/500\n",
            "26/26 [==============================] - 0s 474us/sample - loss: 1.9538 - acc: 0.3333\n",
            "Epoch 107/500\n",
            "26/26 [==============================] - 0s 479us/sample - loss: 2.0785 - acc: 0.2083\n",
            "Epoch 108/500\n",
            "26/26 [==============================] - 0s 586us/sample - loss: 1.9584 - acc: 0.2917\n",
            "Epoch 109/500\n",
            "26/26 [==============================] - 0s 556us/sample - loss: 1.9283 - acc: 0.3333\n",
            "Epoch 110/500\n",
            "26/26 [==============================] - 0s 524us/sample - loss: 1.8986 - acc: 0.4167\n",
            "Epoch 111/500\n",
            "26/26 [==============================] - 0s 496us/sample - loss: 1.8005 - acc: 0.3750\n",
            "Epoch 112/500\n",
            "26/26 [==============================] - 0s 446us/sample - loss: 1.9112 - acc: 0.4167\n",
            "Epoch 113/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 1.8611 - acc: 0.3750\n",
            "Epoch 114/500\n",
            "26/26 [==============================] - 0s 648us/sample - loss: 1.8500 - acc: 0.4167\n",
            "Epoch 115/500\n",
            "26/26 [==============================] - 0s 478us/sample - loss: 1.9011 - acc: 0.3333\n",
            "Epoch 116/500\n",
            "26/26 [==============================] - 0s 567us/sample - loss: 1.9656 - acc: 0.2500\n",
            "Epoch 117/500\n",
            "26/26 [==============================] - 0s 485us/sample - loss: 1.7985 - acc: 0.4583\n",
            "Epoch 118/500\n",
            "26/26 [==============================] - 0s 525us/sample - loss: 1.8976 - acc: 0.3750\n",
            "Epoch 119/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 1.8591 - acc: 0.3750\n",
            "Epoch 120/500\n",
            "26/26 [==============================] - 0s 678us/sample - loss: 1.8993 - acc: 0.3333\n",
            "Epoch 121/500\n",
            "26/26 [==============================] - 0s 598us/sample - loss: 1.8434 - acc: 0.3750\n",
            "Epoch 122/500\n",
            "26/26 [==============================] - 0s 540us/sample - loss: 1.7492 - acc: 0.3750\n",
            "Epoch 123/500\n",
            "26/26 [==============================] - 0s 559us/sample - loss: 1.9586 - acc: 0.2500\n",
            "Epoch 124/500\n",
            "26/26 [==============================] - 0s 492us/sample - loss: 1.8087 - acc: 0.4583\n",
            "Epoch 125/500\n",
            "26/26 [==============================] - 0s 501us/sample - loss: 1.7555 - acc: 0.5417\n",
            "Epoch 126/500\n",
            "26/26 [==============================] - 0s 484us/sample - loss: 1.6829 - acc: 0.5000\n",
            "Epoch 127/500\n",
            "26/26 [==============================] - 0s 549us/sample - loss: 1.8639 - acc: 0.3750\n",
            "Epoch 128/500\n",
            "26/26 [==============================] - 0s 453us/sample - loss: 1.7607 - acc: 0.2917\n",
            "Epoch 129/500\n",
            "26/26 [==============================] - 0s 475us/sample - loss: 1.7404 - acc: 0.5000\n",
            "Epoch 130/500\n",
            "26/26 [==============================] - 0s 571us/sample - loss: 1.8848 - acc: 0.3750\n",
            "Epoch 131/500\n",
            "26/26 [==============================] - 0s 1ms/sample - loss: 1.7734 - acc: 0.4167\n",
            "Epoch 132/500\n",
            "26/26 [==============================] - 0s 510us/sample - loss: 1.7074 - acc: 0.5833\n",
            "Epoch 133/500\n",
            "26/26 [==============================] - 0s 514us/sample - loss: 1.8673 - acc: 0.3750\n",
            "Epoch 134/500\n",
            "26/26 [==============================] - 0s 592us/sample - loss: 1.5748 - acc: 0.5833\n",
            "Epoch 135/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 1.8473 - acc: 0.4167\n",
            "Epoch 136/500\n",
            "26/26 [==============================] - 0s 614us/sample - loss: 1.6523 - acc: 0.5417\n",
            "Epoch 137/500\n",
            "26/26 [==============================] - 0s 571us/sample - loss: 1.8415 - acc: 0.3333\n",
            "Epoch 138/500\n",
            "26/26 [==============================] - 0s 515us/sample - loss: 1.6891 - acc: 0.5000\n",
            "Epoch 139/500\n",
            "26/26 [==============================] - 0s 535us/sample - loss: 1.7120 - acc: 0.4583\n",
            "Epoch 140/500\n",
            "26/26 [==============================] - 0s 509us/sample - loss: 1.7668 - acc: 0.4167\n",
            "Epoch 141/500\n",
            "26/26 [==============================] - 0s 543us/sample - loss: 1.6676 - acc: 0.5000\n",
            "Epoch 142/500\n",
            "26/26 [==============================] - 0s 504us/sample - loss: 1.6297 - acc: 0.5000\n",
            "Epoch 143/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 1.6187 - acc: 0.5417\n",
            "Epoch 144/500\n",
            "26/26 [==============================] - 0s 510us/sample - loss: 1.6644 - acc: 0.5000\n",
            "Epoch 145/500\n",
            "26/26 [==============================] - 0s 440us/sample - loss: 1.7642 - acc: 0.2917\n",
            "Epoch 146/500\n",
            "26/26 [==============================] - 0s 506us/sample - loss: 1.6758 - acc: 0.5833\n",
            "Epoch 147/500\n",
            "26/26 [==============================] - 0s 476us/sample - loss: 1.5736 - acc: 0.5000\n",
            "Epoch 148/500\n",
            "26/26 [==============================] - 0s 470us/sample - loss: 1.6562 - acc: 0.4167\n",
            "Epoch 149/500\n",
            "26/26 [==============================] - 0s 483us/sample - loss: 1.7282 - acc: 0.3750\n",
            "Epoch 150/500\n",
            "26/26 [==============================] - 0s 553us/sample - loss: 1.6213 - acc: 0.5833\n",
            "Epoch 151/500\n",
            "26/26 [==============================] - 0s 643us/sample - loss: 1.5767 - acc: 0.5000\n",
            "Epoch 152/500\n",
            "26/26 [==============================] - 0s 461us/sample - loss: 1.5966 - acc: 0.5417\n",
            "Epoch 153/500\n",
            "26/26 [==============================] - 0s 498us/sample - loss: 1.6259 - acc: 0.5000\n",
            "Epoch 154/500\n",
            "26/26 [==============================] - 0s 487us/sample - loss: 1.6343 - acc: 0.5833\n",
            "Epoch 155/500\n",
            "26/26 [==============================] - 0s 522us/sample - loss: 1.6114 - acc: 0.6250\n",
            "Epoch 156/500\n",
            "26/26 [==============================] - 0s 520us/sample - loss: 1.5898 - acc: 0.4583\n",
            "Epoch 157/500\n",
            "26/26 [==============================] - 0s 525us/sample - loss: 1.6022 - acc: 0.5417\n",
            "Epoch 158/500\n",
            "26/26 [==============================] - 0s 569us/sample - loss: 1.6515 - acc: 0.4167\n",
            "Epoch 159/500\n",
            "26/26 [==============================] - 0s 604us/sample - loss: 1.6094 - acc: 0.4167\n",
            "Epoch 160/500\n",
            "26/26 [==============================] - 0s 533us/sample - loss: 1.5268 - acc: 0.4167\n",
            "Epoch 161/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 1.6149 - acc: 0.5417\n",
            "Epoch 162/500\n",
            "26/26 [==============================] - 0s 447us/sample - loss: 1.4856 - acc: 0.4583\n",
            "Epoch 163/500\n",
            "26/26 [==============================] - 0s 503us/sample - loss: 1.6147 - acc: 0.5417\n",
            "Epoch 164/500\n",
            "26/26 [==============================] - 0s 726us/sample - loss: 1.6300 - acc: 0.5000\n",
            "Epoch 165/500\n",
            "26/26 [==============================] - 0s 465us/sample - loss: 1.5375 - acc: 0.5833\n",
            "Epoch 166/500\n",
            "26/26 [==============================] - 0s 549us/sample - loss: 1.4402 - acc: 0.6667\n",
            "Epoch 167/500\n",
            "26/26 [==============================] - 0s 496us/sample - loss: 1.5346 - acc: 0.5417\n",
            "Epoch 168/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 1.5034 - acc: 0.7083\n",
            "Epoch 169/500\n",
            "26/26 [==============================] - 0s 942us/sample - loss: 1.5988 - acc: 0.4583\n",
            "Epoch 170/500\n",
            "26/26 [==============================] - 0s 664us/sample - loss: 1.5717 - acc: 0.6250\n",
            "Epoch 171/500\n",
            "26/26 [==============================] - 0s 850us/sample - loss: 1.4852 - acc: 0.5000\n",
            "Epoch 172/500\n",
            "26/26 [==============================] - 0s 509us/sample - loss: 1.5882 - acc: 0.5000\n",
            "Epoch 173/500\n",
            "26/26 [==============================] - 0s 534us/sample - loss: 1.5271 - acc: 0.5833\n",
            "Epoch 174/500\n",
            "26/26 [==============================] - 0s 569us/sample - loss: 1.3665 - acc: 0.7083\n",
            "Epoch 175/500\n",
            "26/26 [==============================] - 0s 524us/sample - loss: 1.3534 - acc: 0.6667\n",
            "Epoch 176/500\n",
            "26/26 [==============================] - 0s 462us/sample - loss: 1.5531 - acc: 0.5833\n",
            "Epoch 177/500\n",
            "26/26 [==============================] - 0s 547us/sample - loss: 1.4214 - acc: 0.5417\n",
            "Epoch 178/500\n",
            "26/26 [==============================] - 0s 540us/sample - loss: 1.5126 - acc: 0.5000\n",
            "Epoch 179/500\n",
            "26/26 [==============================] - 0s 516us/sample - loss: 1.3330 - acc: 0.7500\n",
            "Epoch 180/500\n",
            "26/26 [==============================] - 0s 453us/sample - loss: 1.3548 - acc: 0.7083\n",
            "Epoch 181/500\n",
            "26/26 [==============================] - 0s 410us/sample - loss: 1.4541 - acc: 0.5417\n",
            "Epoch 182/500\n",
            "26/26 [==============================] - 0s 499us/sample - loss: 1.2894 - acc: 0.5417\n",
            "Epoch 183/500\n",
            "26/26 [==============================] - 0s 498us/sample - loss: 1.3201 - acc: 0.6250\n",
            "Epoch 184/500\n",
            "26/26 [==============================] - 0s 474us/sample - loss: 1.5682 - acc: 0.4583\n",
            "Epoch 185/500\n",
            "26/26 [==============================] - 0s 493us/sample - loss: 1.5105 - acc: 0.5000\n",
            "Epoch 186/500\n",
            "26/26 [==============================] - 0s 497us/sample - loss: 1.3467 - acc: 0.6250\n",
            "Epoch 187/500\n",
            "26/26 [==============================] - 0s 444us/sample - loss: 1.5001 - acc: 0.3750\n",
            "Epoch 188/500\n",
            "26/26 [==============================] - 0s 421us/sample - loss: 1.6027 - acc: 0.4583\n",
            "Epoch 189/500\n",
            "26/26 [==============================] - 0s 678us/sample - loss: 1.4066 - acc: 0.5417\n",
            "Epoch 190/500\n",
            "26/26 [==============================] - 0s 491us/sample - loss: 1.4458 - acc: 0.6250\n",
            "Epoch 191/500\n",
            "26/26 [==============================] - 0s 454us/sample - loss: 1.3798 - acc: 0.5833\n",
            "Epoch 192/500\n",
            "26/26 [==============================] - 0s 554us/sample - loss: 1.3814 - acc: 0.5833\n",
            "Epoch 193/500\n",
            "26/26 [==============================] - 0s 563us/sample - loss: 1.3760 - acc: 0.7083\n",
            "Epoch 194/500\n",
            "26/26 [==============================] - 0s 560us/sample - loss: 1.2807 - acc: 0.7917\n",
            "Epoch 195/500\n",
            "26/26 [==============================] - 0s 486us/sample - loss: 1.4878 - acc: 0.5417\n",
            "Epoch 196/500\n",
            "26/26 [==============================] - 0s 479us/sample - loss: 1.4262 - acc: 0.5417\n",
            "Epoch 197/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 1.3191 - acc: 0.6250\n",
            "Epoch 198/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 1.3792 - acc: 0.5833\n",
            "Epoch 199/500\n",
            "26/26 [==============================] - 0s 617us/sample - loss: 1.3070 - acc: 0.6250\n",
            "Epoch 200/500\n",
            "26/26 [==============================] - 0s 631us/sample - loss: 1.3971 - acc: 0.4583\n",
            "Epoch 201/500\n",
            "26/26 [==============================] - 0s 513us/sample - loss: 1.2601 - acc: 0.6250\n",
            "Epoch 202/500\n",
            "26/26 [==============================] - 0s 588us/sample - loss: 1.3646 - acc: 0.5417\n",
            "Epoch 203/500\n",
            "26/26 [==============================] - 0s 463us/sample - loss: 1.1954 - acc: 0.6250\n",
            "Epoch 204/500\n",
            "26/26 [==============================] - 0s 456us/sample - loss: 1.4896 - acc: 0.4583\n",
            "Epoch 205/500\n",
            "26/26 [==============================] - 0s 484us/sample - loss: 1.3721 - acc: 0.5833\n",
            "Epoch 206/500\n",
            "26/26 [==============================] - 0s 485us/sample - loss: 1.2110 - acc: 0.6250\n",
            "Epoch 207/500\n",
            "26/26 [==============================] - 0s 542us/sample - loss: 1.1941 - acc: 0.7500\n",
            "Epoch 208/500\n",
            "26/26 [==============================] - 0s 438us/sample - loss: 1.2637 - acc: 0.7083\n",
            "Epoch 209/500\n",
            "26/26 [==============================] - 0s 568us/sample - loss: 1.1824 - acc: 0.6667\n",
            "Epoch 210/500\n",
            "26/26 [==============================] - 0s 540us/sample - loss: 1.2910 - acc: 0.6667\n",
            "Epoch 211/500\n",
            "26/26 [==============================] - 0s 481us/sample - loss: 1.3616 - acc: 0.5833\n",
            "Epoch 212/500\n",
            "26/26 [==============================] - 0s 442us/sample - loss: 1.0939 - acc: 0.8333\n",
            "Epoch 213/500\n",
            "26/26 [==============================] - 0s 556us/sample - loss: 1.2777 - acc: 0.5833\n",
            "Epoch 214/500\n",
            "26/26 [==============================] - 0s 463us/sample - loss: 1.2673 - acc: 0.6250\n",
            "Epoch 215/500\n",
            "26/26 [==============================] - 0s 554us/sample - loss: 1.2687 - acc: 0.6667\n",
            "Epoch 216/500\n",
            "26/26 [==============================] - 0s 538us/sample - loss: 1.2483 - acc: 0.7083\n",
            "Epoch 217/500\n",
            "26/26 [==============================] - 0s 454us/sample - loss: 1.1871 - acc: 0.6250\n",
            "Epoch 218/500\n",
            "26/26 [==============================] - 0s 625us/sample - loss: 1.2543 - acc: 0.6667\n",
            "Epoch 219/500\n",
            "26/26 [==============================] - 0s 791us/sample - loss: 1.2784 - acc: 0.5833\n",
            "Epoch 220/500\n",
            "26/26 [==============================] - 0s 577us/sample - loss: 1.1682 - acc: 0.6667\n",
            "Epoch 221/500\n",
            "26/26 [==============================] - 0s 600us/sample - loss: 1.2473 - acc: 0.6250\n",
            "Epoch 222/500\n",
            "26/26 [==============================] - 0s 509us/sample - loss: 1.3022 - acc: 0.7083\n",
            "Epoch 223/500\n",
            "26/26 [==============================] - 0s 574us/sample - loss: 1.2259 - acc: 0.7083\n",
            "Epoch 224/500\n",
            "26/26 [==============================] - 0s 556us/sample - loss: 1.1425 - acc: 0.6667\n",
            "Epoch 225/500\n",
            "26/26 [==============================] - 0s 491us/sample - loss: 1.2618 - acc: 0.5000\n",
            "Epoch 226/500\n",
            "26/26 [==============================] - 0s 571us/sample - loss: 1.1103 - acc: 0.7500\n",
            "Epoch 227/500\n",
            "26/26 [==============================] - 0s 636us/sample - loss: 1.2700 - acc: 0.5000\n",
            "Epoch 228/500\n",
            "26/26 [==============================] - 0s 671us/sample - loss: 1.1003 - acc: 0.7500\n",
            "Epoch 229/500\n",
            "26/26 [==============================] - 0s 461us/sample - loss: 1.1579 - acc: 0.6250\n",
            "Epoch 230/500\n",
            "26/26 [==============================] - 0s 418us/sample - loss: 1.2868 - acc: 0.5000\n",
            "Epoch 231/500\n",
            "26/26 [==============================] - 0s 455us/sample - loss: 1.0498 - acc: 0.7917\n",
            "Epoch 232/500\n",
            "26/26 [==============================] - 0s 521us/sample - loss: 1.2080 - acc: 0.6250\n",
            "Epoch 233/500\n",
            "26/26 [==============================] - 0s 571us/sample - loss: 1.1338 - acc: 0.5833\n",
            "Epoch 234/500\n",
            "26/26 [==============================] - 0s 600us/sample - loss: 1.1372 - acc: 0.6667\n",
            "Epoch 235/500\n",
            "26/26 [==============================] - 0s 439us/sample - loss: 1.1708 - acc: 0.7500\n",
            "Epoch 236/500\n",
            "26/26 [==============================] - 0s 540us/sample - loss: 1.1974 - acc: 0.6250\n",
            "Epoch 237/500\n",
            "26/26 [==============================] - 0s 515us/sample - loss: 1.2107 - acc: 0.5833\n",
            "Epoch 238/500\n",
            "26/26 [==============================] - 0s 515us/sample - loss: 1.2707 - acc: 0.4583\n",
            "Epoch 239/500\n",
            "26/26 [==============================] - 0s 493us/sample - loss: 1.1552 - acc: 0.7500\n",
            "Epoch 240/500\n",
            "26/26 [==============================] - 0s 524us/sample - loss: 1.1831 - acc: 0.6250\n",
            "Epoch 241/500\n",
            "26/26 [==============================] - 0s 458us/sample - loss: 1.0653 - acc: 0.7083\n",
            "Epoch 242/500\n",
            "26/26 [==============================] - 0s 457us/sample - loss: 1.0659 - acc: 0.7500\n",
            "Epoch 243/500\n",
            "26/26 [==============================] - 0s 478us/sample - loss: 1.2062 - acc: 0.6250\n",
            "Epoch 244/500\n",
            "26/26 [==============================] - 0s 486us/sample - loss: 1.1815 - acc: 0.6667\n",
            "Epoch 245/500\n",
            "26/26 [==============================] - 0s 451us/sample - loss: 1.1533 - acc: 0.6667\n",
            "Epoch 246/500\n",
            "26/26 [==============================] - 0s 456us/sample - loss: 1.0967 - acc: 0.7083\n",
            "Epoch 247/500\n",
            "26/26 [==============================] - 0s 554us/sample - loss: 1.0629 - acc: 0.7917\n",
            "Epoch 248/500\n",
            "26/26 [==============================] - 0s 608us/sample - loss: 1.1216 - acc: 0.5833\n",
            "Epoch 249/500\n",
            "26/26 [==============================] - 0s 566us/sample - loss: 1.1030 - acc: 0.7083\n",
            "Epoch 250/500\n",
            "26/26 [==============================] - 0s 538us/sample - loss: 0.9583 - acc: 0.7917\n",
            "Epoch 251/500\n",
            "26/26 [==============================] - 0s 487us/sample - loss: 1.1709 - acc: 0.5833\n",
            "Epoch 252/500\n",
            "26/26 [==============================] - 0s 488us/sample - loss: 1.0533 - acc: 0.7917\n",
            "Epoch 253/500\n",
            "26/26 [==============================] - 0s 421us/sample - loss: 1.1248 - acc: 0.7500\n",
            "Epoch 254/500\n",
            "26/26 [==============================] - 0s 526us/sample - loss: 1.1882 - acc: 0.5417\n",
            "Epoch 255/500\n",
            "26/26 [==============================] - 0s 566us/sample - loss: 1.1647 - acc: 0.6250\n",
            "Epoch 256/500\n",
            "26/26 [==============================] - 0s 558us/sample - loss: 1.0661 - acc: 0.7500\n",
            "Epoch 257/500\n",
            "26/26 [==============================] - 0s 551us/sample - loss: 0.9874 - acc: 0.7917\n",
            "Epoch 258/500\n",
            "26/26 [==============================] - 0s 474us/sample - loss: 1.0278 - acc: 0.7083\n",
            "Epoch 259/500\n",
            "26/26 [==============================] - 0s 490us/sample - loss: 1.0666 - acc: 0.7083\n",
            "Epoch 260/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 1.1203 - acc: 0.6250\n",
            "Epoch 261/500\n",
            "26/26 [==============================] - 0s 479us/sample - loss: 1.0106 - acc: 0.7083\n",
            "Epoch 262/500\n",
            "26/26 [==============================] - 0s 517us/sample - loss: 1.0249 - acc: 0.7917\n",
            "Epoch 263/500\n",
            "26/26 [==============================] - 0s 506us/sample - loss: 0.9986 - acc: 0.6667\n",
            "Epoch 264/500\n",
            "26/26 [==============================] - 0s 514us/sample - loss: 1.0186 - acc: 0.7083\n",
            "Epoch 265/500\n",
            "26/26 [==============================] - 0s 713us/sample - loss: 1.1052 - acc: 0.6667\n",
            "Epoch 266/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 1.1469 - acc: 0.6250\n",
            "Epoch 267/500\n",
            "26/26 [==============================] - 0s 570us/sample - loss: 1.0361 - acc: 0.7917\n",
            "Epoch 268/500\n",
            "26/26 [==============================] - 0s 547us/sample - loss: 0.9795 - acc: 0.7917\n",
            "Epoch 269/500\n",
            "26/26 [==============================] - 0s 529us/sample - loss: 0.9551 - acc: 0.7500\n",
            "Epoch 270/500\n",
            "26/26 [==============================] - 0s 855us/sample - loss: 0.9226 - acc: 0.8333\n",
            "Epoch 271/500\n",
            "26/26 [==============================] - 0s 712us/sample - loss: 0.9235 - acc: 0.8333\n",
            "Epoch 272/500\n",
            "26/26 [==============================] - 0s 656us/sample - loss: 0.9746 - acc: 0.7917\n",
            "Epoch 273/500\n",
            "26/26 [==============================] - 0s 561us/sample - loss: 0.9650 - acc: 0.7083\n",
            "Epoch 274/500\n",
            "26/26 [==============================] - 0s 457us/sample - loss: 0.9342 - acc: 0.7500\n",
            "Epoch 275/500\n",
            "26/26 [==============================] - 0s 633us/sample - loss: 0.9974 - acc: 0.7917\n",
            "Epoch 276/500\n",
            "26/26 [==============================] - 0s 744us/sample - loss: 1.0472 - acc: 0.7083\n",
            "Epoch 277/500\n",
            "26/26 [==============================] - 0s 537us/sample - loss: 0.9993 - acc: 0.7500\n",
            "Epoch 278/500\n",
            "26/26 [==============================] - 0s 537us/sample - loss: 0.9162 - acc: 0.7500\n",
            "Epoch 279/500\n",
            "26/26 [==============================] - 0s 496us/sample - loss: 0.8987 - acc: 0.8333\n",
            "Epoch 280/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 1.0481 - acc: 0.6667\n",
            "Epoch 281/500\n",
            "26/26 [==============================] - 0s 621us/sample - loss: 0.9240 - acc: 0.8333\n",
            "Epoch 282/500\n",
            "26/26 [==============================] - 0s 494us/sample - loss: 0.9751 - acc: 0.7917\n",
            "Epoch 283/500\n",
            "26/26 [==============================] - 0s 456us/sample - loss: 0.9648 - acc: 0.7083\n",
            "Epoch 284/500\n",
            "26/26 [==============================] - 0s 587us/sample - loss: 0.9624 - acc: 0.7083\n",
            "Epoch 285/500\n",
            "26/26 [==============================] - 0s 619us/sample - loss: 0.9712 - acc: 0.8333\n",
            "Epoch 286/500\n",
            "26/26 [==============================] - 0s 480us/sample - loss: 0.9150 - acc: 0.7917\n",
            "Epoch 287/500\n",
            "26/26 [==============================] - 0s 659us/sample - loss: 0.9955 - acc: 0.7500\n",
            "Epoch 288/500\n",
            "26/26 [==============================] - 0s 634us/sample - loss: 0.9304 - acc: 0.7917\n",
            "Epoch 289/500\n",
            "26/26 [==============================] - 0s 575us/sample - loss: 0.9612 - acc: 0.6250\n",
            "Epoch 290/500\n",
            "26/26 [==============================] - 0s 464us/sample - loss: 0.9130 - acc: 0.7917\n",
            "Epoch 291/500\n",
            "26/26 [==============================] - 0s 521us/sample - loss: 0.9848 - acc: 0.7917\n",
            "Epoch 292/500\n",
            "26/26 [==============================] - 0s 477us/sample - loss: 0.8978 - acc: 0.7083\n",
            "Epoch 293/500\n",
            "26/26 [==============================] - 0s 447us/sample - loss: 0.8088 - acc: 0.8750\n",
            "Epoch 294/500\n",
            "26/26 [==============================] - 0s 572us/sample - loss: 0.9572 - acc: 0.7083\n",
            "Epoch 295/500\n",
            "26/26 [==============================] - 0s 529us/sample - loss: 0.8597 - acc: 0.8750\n",
            "Epoch 296/500\n",
            "26/26 [==============================] - 0s 478us/sample - loss: 0.8884 - acc: 0.7500\n",
            "Epoch 297/500\n",
            "26/26 [==============================] - 0s 557us/sample - loss: 0.9605 - acc: 0.7500\n",
            "Epoch 298/500\n",
            "26/26 [==============================] - 0s 457us/sample - loss: 0.9262 - acc: 0.7083\n",
            "Epoch 299/500\n",
            "26/26 [==============================] - 0s 441us/sample - loss: 0.9264 - acc: 0.7917\n",
            "Epoch 300/500\n",
            "26/26 [==============================] - 0s 461us/sample - loss: 0.8701 - acc: 0.7917\n",
            "Epoch 301/500\n",
            "26/26 [==============================] - 0s 452us/sample - loss: 0.9001 - acc: 0.8750\n",
            "Epoch 302/500\n",
            "26/26 [==============================] - 0s 444us/sample - loss: 0.8804 - acc: 0.8750\n",
            "Epoch 303/500\n",
            "26/26 [==============================] - 0s 483us/sample - loss: 0.9453 - acc: 0.6667\n",
            "Epoch 304/500\n",
            "26/26 [==============================] - 0s 663us/sample - loss: 0.9204 - acc: 0.7500\n",
            "Epoch 305/500\n",
            "26/26 [==============================] - 0s 462us/sample - loss: 0.7935 - acc: 0.7917\n",
            "Epoch 306/500\n",
            "26/26 [==============================] - 0s 437us/sample - loss: 0.9126 - acc: 0.7500\n",
            "Epoch 307/500\n",
            "26/26 [==============================] - 0s 567us/sample - loss: 0.8722 - acc: 0.7917\n",
            "Epoch 308/500\n",
            "26/26 [==============================] - 0s 480us/sample - loss: 0.8517 - acc: 0.7917\n",
            "Epoch 309/500\n",
            "26/26 [==============================] - 0s 529us/sample - loss: 0.8746 - acc: 0.7917\n",
            "Epoch 310/500\n",
            "26/26 [==============================] - 0s 922us/sample - loss: 0.8547 - acc: 0.7917\n",
            "Epoch 311/500\n",
            "26/26 [==============================] - 0s 538us/sample - loss: 0.8197 - acc: 0.7500\n",
            "Epoch 312/500\n",
            "26/26 [==============================] - 0s 538us/sample - loss: 0.8640 - acc: 0.7083\n",
            "Epoch 313/500\n",
            "26/26 [==============================] - 0s 570us/sample - loss: 0.8973 - acc: 0.6667\n",
            "Epoch 314/500\n",
            "26/26 [==============================] - 0s 568us/sample - loss: 0.7174 - acc: 0.9167\n",
            "Epoch 315/500\n",
            "26/26 [==============================] - 0s 467us/sample - loss: 0.8374 - acc: 0.7083\n",
            "Epoch 316/500\n",
            "26/26 [==============================] - 0s 444us/sample - loss: 0.8871 - acc: 0.7500\n",
            "Epoch 317/500\n",
            "26/26 [==============================] - 0s 520us/sample - loss: 0.9213 - acc: 0.7917\n",
            "Epoch 318/500\n",
            "26/26 [==============================] - 0s 520us/sample - loss: 0.7142 - acc: 0.8750\n",
            "Epoch 319/500\n",
            "26/26 [==============================] - 0s 753us/sample - loss: 0.8390 - acc: 0.8333\n",
            "Epoch 320/500\n",
            "26/26 [==============================] - 0s 533us/sample - loss: 0.7772 - acc: 0.9167\n",
            "Epoch 321/500\n",
            "26/26 [==============================] - 0s 507us/sample - loss: 0.8830 - acc: 0.7083\n",
            "Epoch 322/500\n",
            "26/26 [==============================] - 0s 533us/sample - loss: 0.8680 - acc: 0.7500\n",
            "Epoch 323/500\n",
            "26/26 [==============================] - 0s 497us/sample - loss: 0.8037 - acc: 0.7500\n",
            "Epoch 324/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 0.9268 - acc: 0.7500\n",
            "Epoch 325/500\n",
            "26/26 [==============================] - 0s 579us/sample - loss: 0.8202 - acc: 0.7083\n",
            "Epoch 326/500\n",
            "26/26 [==============================] - 0s 485us/sample - loss: 0.8376 - acc: 0.7500\n",
            "Epoch 327/500\n",
            "26/26 [==============================] - 0s 559us/sample - loss: 0.8076 - acc: 0.7917\n",
            "Epoch 328/500\n",
            "26/26 [==============================] - 0s 433us/sample - loss: 0.7602 - acc: 0.8750\n",
            "Epoch 329/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 0.8211 - acc: 0.8333\n",
            "Epoch 330/500\n",
            "26/26 [==============================] - 0s 578us/sample - loss: 0.8471 - acc: 0.8333\n",
            "Epoch 331/500\n",
            "26/26 [==============================] - 0s 489us/sample - loss: 0.6956 - acc: 0.8750\n",
            "Epoch 332/500\n",
            "26/26 [==============================] - 0s 761us/sample - loss: 0.7097 - acc: 0.8750\n",
            "Epoch 333/500\n",
            "26/26 [==============================] - 0s 635us/sample - loss: 0.7312 - acc: 0.8333\n",
            "Epoch 334/500\n",
            "26/26 [==============================] - 0s 452us/sample - loss: 0.7814 - acc: 0.8333\n",
            "Epoch 335/500\n",
            "26/26 [==============================] - 0s 445us/sample - loss: 0.8586 - acc: 0.7917\n",
            "Epoch 336/500\n",
            "26/26 [==============================] - 0s 597us/sample - loss: 0.7863 - acc: 0.8333\n",
            "Epoch 337/500\n",
            "26/26 [==============================] - 0s 643us/sample - loss: 0.7685 - acc: 0.8750\n",
            "Epoch 338/500\n",
            "26/26 [==============================] - 0s 528us/sample - loss: 0.8298 - acc: 0.8333\n",
            "Epoch 339/500\n",
            "26/26 [==============================] - 0s 550us/sample - loss: 0.6482 - acc: 0.8750\n",
            "Epoch 340/500\n",
            "26/26 [==============================] - 0s 477us/sample - loss: 0.8061 - acc: 0.7500\n",
            "Epoch 341/500\n",
            "26/26 [==============================] - 0s 527us/sample - loss: 0.7623 - acc: 0.7083\n",
            "Epoch 342/500\n",
            "26/26 [==============================] - 0s 579us/sample - loss: 0.7990 - acc: 0.8333\n",
            "Epoch 343/500\n",
            "26/26 [==============================] - 0s 499us/sample - loss: 0.8638 - acc: 0.7083\n",
            "Epoch 344/500\n",
            "26/26 [==============================] - 0s 537us/sample - loss: 0.9228 - acc: 0.6667\n",
            "Epoch 345/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 0.7669 - acc: 0.9167\n",
            "Epoch 346/500\n",
            "26/26 [==============================] - 0s 469us/sample - loss: 0.9271 - acc: 0.7083\n",
            "Epoch 347/500\n",
            "26/26 [==============================] - 0s 469us/sample - loss: 0.7883 - acc: 0.8750\n",
            "Epoch 348/500\n",
            "26/26 [==============================] - 0s 628us/sample - loss: 0.7578 - acc: 0.8333\n",
            "Epoch 349/500\n",
            "26/26 [==============================] - 0s 506us/sample - loss: 0.7965 - acc: 0.7500\n",
            "Epoch 350/500\n",
            "26/26 [==============================] - 0s 561us/sample - loss: 0.8421 - acc: 0.8333\n",
            "Epoch 351/500\n",
            "26/26 [==============================] - 0s 532us/sample - loss: 0.8661 - acc: 0.7083\n",
            "Epoch 352/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 0.6926 - acc: 0.8750\n",
            "Epoch 353/500\n",
            "26/26 [==============================] - 0s 580us/sample - loss: 0.7810 - acc: 0.7917\n",
            "Epoch 354/500\n",
            "26/26 [==============================] - 0s 528us/sample - loss: 0.7800 - acc: 0.8333\n",
            "Epoch 355/500\n",
            "26/26 [==============================] - 0s 564us/sample - loss: 0.7748 - acc: 0.7500\n",
            "Epoch 356/500\n",
            "26/26 [==============================] - 0s 565us/sample - loss: 0.7726 - acc: 0.7083\n",
            "Epoch 357/500\n",
            "26/26 [==============================] - 0s 486us/sample - loss: 0.7766 - acc: 0.8333\n",
            "Epoch 358/500\n",
            "26/26 [==============================] - 0s 589us/sample - loss: 0.8265 - acc: 0.7500\n",
            "Epoch 359/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 0.7761 - acc: 0.8750\n",
            "Epoch 360/500\n",
            "26/26 [==============================] - 0s 621us/sample - loss: 0.8774 - acc: 0.6250\n",
            "Epoch 361/500\n",
            "26/26 [==============================] - 0s 589us/sample - loss: 0.7385 - acc: 0.8750\n",
            "Epoch 362/500\n",
            "26/26 [==============================] - 0s 477us/sample - loss: 0.7712 - acc: 0.7917\n",
            "Epoch 363/500\n",
            "26/26 [==============================] - 0s 535us/sample - loss: 0.7360 - acc: 0.9167\n",
            "Epoch 364/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 0.7594 - acc: 0.8333\n",
            "Epoch 365/500\n",
            "26/26 [==============================] - 0s 512us/sample - loss: 0.8146 - acc: 0.7083\n",
            "Epoch 366/500\n",
            "26/26 [==============================] - 0s 548us/sample - loss: 0.7132 - acc: 0.7917\n",
            "Epoch 367/500\n",
            "26/26 [==============================] - 0s 583us/sample - loss: 0.6449 - acc: 0.8333\n",
            "Epoch 368/500\n",
            "26/26 [==============================] - 0s 1ms/sample - loss: 0.7748 - acc: 0.7500\n",
            "Epoch 369/500\n",
            "26/26 [==============================] - 0s 1ms/sample - loss: 0.6759 - acc: 0.8333\n",
            "Epoch 370/500\n",
            "26/26 [==============================] - 0s 469us/sample - loss: 0.6527 - acc: 0.8333\n",
            "Epoch 371/500\n",
            "26/26 [==============================] - 0s 471us/sample - loss: 0.8142 - acc: 0.7500\n",
            "Epoch 372/500\n",
            "26/26 [==============================] - 0s 534us/sample - loss: 0.7533 - acc: 0.8333\n",
            "Epoch 373/500\n",
            "26/26 [==============================] - 0s 523us/sample - loss: 0.6288 - acc: 0.9583\n",
            "Epoch 374/500\n",
            "26/26 [==============================] - 0s 489us/sample - loss: 0.7107 - acc: 0.9167\n",
            "Epoch 375/500\n",
            "26/26 [==============================] - 0s 489us/sample - loss: 0.6549 - acc: 0.8750\n",
            "Epoch 376/500\n",
            "26/26 [==============================] - 0s 532us/sample - loss: 0.5715 - acc: 0.8750\n",
            "Epoch 377/500\n",
            "26/26 [==============================] - 0s 504us/sample - loss: 0.6681 - acc: 0.8750\n",
            "Epoch 378/500\n",
            "26/26 [==============================] - 0s 609us/sample - loss: 0.6573 - acc: 0.8750\n",
            "Epoch 379/500\n",
            "26/26 [==============================] - 0s 572us/sample - loss: 0.7351 - acc: 0.8333\n",
            "Epoch 380/500\n",
            "26/26 [==============================] - 0s 497us/sample - loss: 0.7869 - acc: 0.7917\n",
            "Epoch 381/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 0.6804 - acc: 0.7917\n",
            "Epoch 382/500\n",
            "26/26 [==============================] - 0s 458us/sample - loss: 0.6331 - acc: 0.8333\n",
            "Epoch 383/500\n",
            "26/26 [==============================] - 0s 494us/sample - loss: 0.6972 - acc: 0.9167\n",
            "Epoch 384/500\n",
            "26/26 [==============================] - 0s 480us/sample - loss: 0.6161 - acc: 0.8333\n",
            "Epoch 385/500\n",
            "26/26 [==============================] - 0s 732us/sample - loss: 0.7790 - acc: 0.7083\n",
            "Epoch 386/500\n",
            "26/26 [==============================] - 0s 470us/sample - loss: 0.6341 - acc: 0.9583\n",
            "Epoch 387/500\n",
            "26/26 [==============================] - 0s 505us/sample - loss: 0.5889 - acc: 0.9583\n",
            "Epoch 388/500\n",
            "26/26 [==============================] - 0s 784us/sample - loss: 0.6071 - acc: 0.8750\n",
            "Epoch 389/500\n",
            "26/26 [==============================] - 0s 542us/sample - loss: 0.7684 - acc: 0.6667\n",
            "Epoch 390/500\n",
            "26/26 [==============================] - 0s 526us/sample - loss: 0.6058 - acc: 0.9167\n",
            "Epoch 391/500\n",
            "26/26 [==============================] - 0s 514us/sample - loss: 0.6425 - acc: 0.8750\n",
            "Epoch 392/500\n",
            "26/26 [==============================] - 0s 442us/sample - loss: 0.7622 - acc: 0.8750\n",
            "Epoch 393/500\n",
            "26/26 [==============================] - 0s 491us/sample - loss: 0.6432 - acc: 0.8750\n",
            "Epoch 394/500\n",
            "26/26 [==============================] - 0s 460us/sample - loss: 0.6548 - acc: 0.8750\n",
            "Epoch 395/500\n",
            "26/26 [==============================] - 0s 440us/sample - loss: 0.6781 - acc: 0.7917\n",
            "Epoch 396/500\n",
            "26/26 [==============================] - 0s 453us/sample - loss: 0.7175 - acc: 0.8333\n",
            "Epoch 397/500\n",
            "26/26 [==============================] - 0s 467us/sample - loss: 0.6371 - acc: 0.7917\n",
            "Epoch 398/500\n",
            "26/26 [==============================] - 0s 511us/sample - loss: 0.7025 - acc: 0.7917\n",
            "Epoch 399/500\n",
            "26/26 [==============================] - 0s 489us/sample - loss: 0.6273 - acc: 0.8750\n",
            "Epoch 400/500\n",
            "26/26 [==============================] - 0s 529us/sample - loss: 0.7185 - acc: 0.7917\n",
            "Epoch 401/500\n",
            "26/26 [==============================] - 0s 540us/sample - loss: 0.7012 - acc: 0.8750\n",
            "Epoch 402/500\n",
            "26/26 [==============================] - 0s 471us/sample - loss: 0.5943 - acc: 0.8750\n",
            "Epoch 403/500\n",
            "26/26 [==============================] - 0s 496us/sample - loss: 0.6408 - acc: 0.7917\n",
            "Epoch 404/500\n",
            "26/26 [==============================] - 0s 678us/sample - loss: 0.5345 - acc: 0.9167\n",
            "Epoch 405/500\n",
            "26/26 [==============================] - 0s 619us/sample - loss: 0.6405 - acc: 0.9167\n",
            "Epoch 406/500\n",
            "26/26 [==============================] - 0s 480us/sample - loss: 0.6533 - acc: 0.8333\n",
            "Epoch 407/500\n",
            "26/26 [==============================] - 0s 491us/sample - loss: 0.6218 - acc: 0.9167\n",
            "Epoch 408/500\n",
            "26/26 [==============================] - 0s 563us/sample - loss: 0.6543 - acc: 0.8333\n",
            "Epoch 409/500\n",
            "26/26 [==============================] - 0s 522us/sample - loss: 0.6252 - acc: 0.8750\n",
            "Epoch 410/500\n",
            "26/26 [==============================] - 0s 459us/sample - loss: 0.5752 - acc: 0.9167\n",
            "Epoch 411/500\n",
            "26/26 [==============================] - 0s 522us/sample - loss: 0.6140 - acc: 0.7917\n",
            "Epoch 412/500\n",
            "26/26 [==============================] - 0s 523us/sample - loss: 0.5807 - acc: 0.8750\n",
            "Epoch 413/500\n",
            "26/26 [==============================] - 0s 545us/sample - loss: 0.6112 - acc: 0.8750\n",
            "Epoch 414/500\n",
            "26/26 [==============================] - 0s 480us/sample - loss: 0.5401 - acc: 0.9167\n",
            "Epoch 415/500\n",
            "26/26 [==============================] - 0s 501us/sample - loss: 0.6374 - acc: 0.7917\n",
            "Epoch 416/500\n",
            "26/26 [==============================] - 0s 554us/sample - loss: 0.6365 - acc: 0.8333\n",
            "Epoch 417/500\n",
            "26/26 [==============================] - 0s 801us/sample - loss: 0.5722 - acc: 0.8750\n",
            "Epoch 418/500\n",
            "26/26 [==============================] - 0s 733us/sample - loss: 0.6010 - acc: 0.9167\n",
            "Epoch 419/500\n",
            "26/26 [==============================] - 0s 456us/sample - loss: 0.6329 - acc: 0.7917\n",
            "Epoch 420/500\n",
            "26/26 [==============================] - 0s 606us/sample - loss: 0.4847 - acc: 0.8750\n",
            "Epoch 421/500\n",
            "26/26 [==============================] - 0s 560us/sample - loss: 0.6853 - acc: 0.8750\n",
            "Epoch 422/500\n",
            "26/26 [==============================] - 0s 599us/sample - loss: 0.6234 - acc: 0.8333\n",
            "Epoch 423/500\n",
            "26/26 [==============================] - 0s 517us/sample - loss: 0.5234 - acc: 0.9583\n",
            "Epoch 424/500\n",
            "26/26 [==============================] - 0s 507us/sample - loss: 0.6347 - acc: 0.8333\n",
            "Epoch 425/500\n",
            "26/26 [==============================] - 0s 589us/sample - loss: 0.5684 - acc: 0.9167\n",
            "Epoch 426/500\n",
            "26/26 [==============================] - 0s 507us/sample - loss: 0.6902 - acc: 0.8333\n",
            "Epoch 427/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 0.6143 - acc: 0.8750\n",
            "Epoch 428/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 0.6833 - acc: 0.8333\n",
            "Epoch 429/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 0.6369 - acc: 0.8333\n",
            "Epoch 430/500\n",
            "26/26 [==============================] - 0s 523us/sample - loss: 0.6335 - acc: 0.8333\n",
            "Epoch 431/500\n",
            "26/26 [==============================] - 0s 521us/sample - loss: 0.6355 - acc: 0.7917\n",
            "Epoch 432/500\n",
            "26/26 [==============================] - 0s 548us/sample - loss: 0.6093 - acc: 0.8333\n",
            "Epoch 433/500\n",
            "26/26 [==============================] - 0s 494us/sample - loss: 0.6009 - acc: 0.8333\n",
            "Epoch 434/500\n",
            "26/26 [==============================] - 0s 601us/sample - loss: 0.5816 - acc: 0.8333\n",
            "Epoch 435/500\n",
            "26/26 [==============================] - 0s 525us/sample - loss: 0.5623 - acc: 0.9583\n",
            "Epoch 436/500\n",
            "26/26 [==============================] - 0s 694us/sample - loss: 0.6023 - acc: 0.8750\n",
            "Epoch 437/500\n",
            "26/26 [==============================] - 0s 621us/sample - loss: 0.6780 - acc: 0.8333\n",
            "Epoch 438/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 0.6203 - acc: 0.8750\n",
            "Epoch 439/500\n",
            "26/26 [==============================] - 0s 565us/sample - loss: 0.5519 - acc: 0.9167\n",
            "Epoch 440/500\n",
            "26/26 [==============================] - 0s 599us/sample - loss: 0.6978 - acc: 0.7500\n",
            "Epoch 441/500\n",
            "26/26 [==============================] - 0s 498us/sample - loss: 0.5910 - acc: 0.7917\n",
            "Epoch 442/500\n",
            "26/26 [==============================] - 0s 452us/sample - loss: 0.5895 - acc: 0.9167\n",
            "Epoch 443/500\n",
            "26/26 [==============================] - 0s 507us/sample - loss: 0.6236 - acc: 0.8750\n",
            "Epoch 444/500\n",
            "26/26 [==============================] - 0s 500us/sample - loss: 0.6037 - acc: 0.8750\n",
            "Epoch 445/500\n",
            "26/26 [==============================] - 0s 472us/sample - loss: 0.6718 - acc: 0.8333\n",
            "Epoch 446/500\n",
            "26/26 [==============================] - 0s 522us/sample - loss: 0.6073 - acc: 0.8333\n",
            "Epoch 447/500\n",
            "26/26 [==============================] - 0s 507us/sample - loss: 0.6372 - acc: 0.8750\n",
            "Epoch 448/500\n",
            "26/26 [==============================] - 0s 556us/sample - loss: 0.5851 - acc: 0.8750\n",
            "Epoch 449/500\n",
            "26/26 [==============================] - 0s 812us/sample - loss: 0.5406 - acc: 0.9583\n",
            "Epoch 450/500\n",
            "26/26 [==============================] - 0s 559us/sample - loss: 0.5855 - acc: 0.9167\n",
            "Epoch 451/500\n",
            "26/26 [==============================] - 0s 695us/sample - loss: 0.4750 - acc: 0.9167\n",
            "Epoch 452/500\n",
            "26/26 [==============================] - 0s 523us/sample - loss: 0.4811 - acc: 0.9583\n",
            "Epoch 453/500\n",
            "26/26 [==============================] - 0s 471us/sample - loss: 0.4920 - acc: 0.8750\n",
            "Epoch 454/500\n",
            "26/26 [==============================] - 0s 483us/sample - loss: 0.6511 - acc: 0.7917\n",
            "Epoch 455/500\n",
            "26/26 [==============================] - 0s 537us/sample - loss: 0.5359 - acc: 0.8750\n",
            "Epoch 456/500\n",
            "26/26 [==============================] - 0s 482us/sample - loss: 0.5028 - acc: 0.9583\n",
            "Epoch 457/500\n",
            "26/26 [==============================] - 0s 520us/sample - loss: 0.5581 - acc: 0.8750\n",
            "Epoch 458/500\n",
            "26/26 [==============================] - 0s 481us/sample - loss: 0.5830 - acc: 0.9167\n",
            "Epoch 459/500\n",
            "26/26 [==============================] - 0s 474us/sample - loss: 0.5972 - acc: 0.8333\n",
            "Epoch 460/500\n",
            "26/26 [==============================] - 0s 559us/sample - loss: 0.5830 - acc: 0.9583\n",
            "Epoch 461/500\n",
            "26/26 [==============================] - 0s 514us/sample - loss: 0.5518 - acc: 0.9167\n",
            "Epoch 462/500\n",
            "26/26 [==============================] - 0s 516us/sample - loss: 0.6393 - acc: 0.8750\n",
            "Epoch 463/500\n",
            "26/26 [==============================] - 0s 628us/sample - loss: 0.5041 - acc: 0.8750\n",
            "Epoch 464/500\n",
            "26/26 [==============================] - 0s 580us/sample - loss: 0.5357 - acc: 0.8750\n",
            "Epoch 465/500\n",
            "26/26 [==============================] - 0s 548us/sample - loss: 0.5458 - acc: 0.8750\n",
            "Epoch 466/500\n",
            "26/26 [==============================] - 0s 809us/sample - loss: 0.5753 - acc: 0.8333\n",
            "Epoch 467/500\n",
            "26/26 [==============================] - 0s 761us/sample - loss: 0.4802 - acc: 0.9167\n",
            "Epoch 468/500\n",
            "26/26 [==============================] - 0s 652us/sample - loss: 0.5747 - acc: 0.8333\n",
            "Epoch 469/500\n",
            "26/26 [==============================] - 0s 526us/sample - loss: 0.6117 - acc: 0.8333\n",
            "Epoch 470/500\n",
            "26/26 [==============================] - 0s 575us/sample - loss: 0.5226 - acc: 0.9167\n",
            "Epoch 471/500\n",
            "26/26 [==============================] - 0s 543us/sample - loss: 0.5357 - acc: 0.8750\n",
            "Epoch 472/500\n",
            "26/26 [==============================] - 0s 836us/sample - loss: 0.5865 - acc: 0.9167\n",
            "Epoch 473/500\n",
            "26/26 [==============================] - 0s 546us/sample - loss: 0.5567 - acc: 0.9583\n",
            "Epoch 474/500\n",
            "26/26 [==============================] - 0s 714us/sample - loss: 0.5142 - acc: 0.8750\n",
            "Epoch 475/500\n",
            "26/26 [==============================] - 0s 734us/sample - loss: 0.5451 - acc: 0.8750\n",
            "Epoch 476/500\n",
            "26/26 [==============================] - 0s 488us/sample - loss: 0.5304 - acc: 0.9167\n",
            "Epoch 477/500\n",
            "26/26 [==============================] - 0s 511us/sample - loss: 0.6342 - acc: 0.7917\n",
            "Epoch 478/500\n",
            "26/26 [==============================] - 0s 544us/sample - loss: 0.4664 - acc: 0.9167\n",
            "Epoch 479/500\n",
            "26/26 [==============================] - 0s 552us/sample - loss: 0.5016 - acc: 0.8750\n",
            "Epoch 480/500\n",
            "26/26 [==============================] - 0s 502us/sample - loss: 0.4896 - acc: 0.8750\n",
            "Epoch 481/500\n",
            "26/26 [==============================] - 0s 467us/sample - loss: 0.5508 - acc: 0.9167\n",
            "Epoch 482/500\n",
            "26/26 [==============================] - 0s 497us/sample - loss: 0.5355 - acc: 0.9167\n",
            "Epoch 483/500\n",
            "26/26 [==============================] - 0s 654us/sample - loss: 0.5372 - acc: 0.9167\n",
            "Epoch 484/500\n",
            "26/26 [==============================] - 0s 532us/sample - loss: 0.5005 - acc: 0.9167\n",
            "Epoch 485/500\n",
            "26/26 [==============================] - 0s 478us/sample - loss: 0.5167 - acc: 0.9583\n",
            "Epoch 486/500\n",
            "26/26 [==============================] - 0s 524us/sample - loss: 0.5202 - acc: 0.8750\n",
            "Epoch 487/500\n",
            "26/26 [==============================] - 0s 509us/sample - loss: 0.4973 - acc: 0.9167\n",
            "Epoch 488/500\n",
            "26/26 [==============================] - 0s 490us/sample - loss: 0.5139 - acc: 0.8750\n",
            "Epoch 489/500\n",
            "26/26 [==============================] - 0s 591us/sample - loss: 0.6195 - acc: 0.8333\n",
            "Epoch 490/500\n",
            "26/26 [==============================] - 0s 527us/sample - loss: 0.4966 - acc: 0.8750\n",
            "Epoch 491/500\n",
            "26/26 [==============================] - 0s 538us/sample - loss: 0.5403 - acc: 0.8750\n",
            "Epoch 492/500\n",
            "26/26 [==============================] - 0s 573us/sample - loss: 0.4741 - acc: 0.9167\n",
            "Epoch 493/500\n",
            "26/26 [==============================] - 0s 536us/sample - loss: 0.4630 - acc: 0.9583\n",
            "Epoch 494/500\n",
            "26/26 [==============================] - 0s 647us/sample - loss: 0.6159 - acc: 0.9167\n",
            "Epoch 495/500\n",
            "26/26 [==============================] - 0s 523us/sample - loss: 0.4027 - acc: 0.9167\n",
            "Epoch 496/500\n",
            "26/26 [==============================] - 0s 518us/sample - loss: 0.4523 - acc: 0.9583\n",
            "Epoch 497/500\n",
            "26/26 [==============================] - 0s 596us/sample - loss: 0.4233 - acc: 0.8750\n",
            "Epoch 498/500\n",
            "26/26 [==============================] - 0s 514us/sample - loss: 0.4449 - acc: 0.9167\n",
            "Epoch 499/500\n",
            "26/26 [==============================] - 0s 508us/sample - loss: 0.5010 - acc: 0.8333\n",
            "Epoch 500/500\n",
            "26/26 [==============================] - 0s 532us/sample - loss: 0.5408 - acc: 0.8750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f94e217c320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "YzZe48vENjUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "3dcfe0f0-4452-4a14-9d6e-67a066661ac7"
      },
      "cell_type": "code",
      "source": [
        "# Create the plot\n",
        "plt.plot(tpu_model.history.history['acc'], 'r', tpu_model.history.history['loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFYCAYAAAB6RnQAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1Yz/B9r+1sgKYYMBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ueawbr1eGsVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "3dae22b1-55b5-4650-874c-710930532953"
      },
      "cell_type": "code",
      "source": [
        "cpu_model = tpu_model.sync_to_cpu()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I4XK5eh-VSb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cpu_model.save_weights('Deep_Writing_with_sentence-word_prediction-tpu.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oml2ac7Vjds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cpu_model.load_weights('Deep_Writing_with_sentence-word_prediction-tpu.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "npQJ92OeXPp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e453fdf8-5ce2-4fde-cc8a-f889ecec0b05"
      },
      "cell_type": "code",
      "source": [
        "print(X[0])\n",
        "X_lstm[0:].shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.         -5.         -3.46410162 -2.76887462 -2.34520788 -2.04939015\n",
            " -1.82574186 -1.64750894 -1.5        -1.37436854 -1.26491106 -1.16774842\n",
            " -1.08012345 -1.         -0.9258201  -0.85634884 -0.79056942 -0.72760688\n",
            " -0.66666667 -0.60697698 -0.54772256 -0.48795004 -0.42640143 -0.36115756\n",
            " -0.28867513 -0.2       ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 26, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "CIE3gxpeGtLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d2ac4623-667d-49b3-df43-8ee43562176b"
      },
      "cell_type": "code",
      "source": [
        "pred = cpu_model.predict(X_lstm[0:])\n",
        "print(pred.shape)\n",
        "line = []\n",
        "for i in range(len(pred)):\n",
        "  line.append(tokenizer.index_word[np.argmax(pred[i])])\n",
        "  \n",
        "' '.join(line)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26, 24)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'think think think any of my adventures with mr sherlock holmes opened quite so abruptly or so dramatically as that which i associate with the thre'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "aNZbZv6HouIB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}