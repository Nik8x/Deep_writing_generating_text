{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of deep_writing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nik8x/Deep_writing_generating_text/blob/master/deep_writing-tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RMw_d0K61LfB",
        "colab_type": "code",
        "outputId": "0a9371fc-9d59-46cf-8046-6fae50bd134e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import regex as re\n",
        "\n",
        "import nltk\n",
        "from nltk.draw.dispersion import dispersion_plot\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.probability import FreqDist\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.util import ngrams\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import urllib\n",
        "\n",
        "import os\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HyGRD5Ea1MgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(\"The current directory is: \", os.getcwd())\n",
        "# import os\n",
        "# os.chdir(\"/content/gdrive/My Drive/Galvanize Adm/Marcel Proust\")\n",
        "# print(\"The current directory is: \", os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oiOtYhrX1bM-",
        "colab_type": "code",
        "outputId": "41cda42a-dd2f-431d-cedf-0fc2908b324b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "txt = urllib.request.urlopen('http://www.textfiles.com/stories/3gables.txt').read().decode('utf8')\n",
        "txt = txt.replace('\\n', ' ')[322:]\n",
        "txt[0:400]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Adveniure of the Three Gables\\r \\r   I don't think that any of my adventures with Mr. Sherlock\\r Holmes opened quite so abruptly, or so dramatically, as that\\r which I associate with The Three Gables. I had not seen Holmes\\r for some days and had no idea of the new channel into which his\\r activities had been directed. He was in a chatty mood that\\r morning, however, and had just settled me into the \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "tu_M1Wo6hDTE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's do some cleaning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSHSwXGsiZQm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = txt.split(' ')\n",
        "words_s = [word.lower() for word in words if word.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3paoUv32pKW5",
        "colab_type": "code",
        "outputId": "5f6691ff-6c76-446a-b2e4-7232e6d08ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "len(words_s)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "kR1w_wAb1516",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# |# creating characters, words and lists \n",
        "# characters = sorted(list(set(txt)))\n",
        "# words = txt.split(' ')\n",
        "# sentences = txt.split('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0hqEFlkX9_fr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # let's remove stop words from words\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "# words_s = [i for i in words if not i in stop_words]\n",
        "# words_s = [word.lower() for word in words_s if word.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKmXGYHv_YoA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fdist = FreqDist(words_s) # checking most frequent words in whole document\n",
        "# plt.figure(figsize= (12,2))\n",
        "# plt.bar(pd.DataFrame(fdist.most_common()[0:20])[0], pd.DataFrame(fdist.most_common()[0:20])[1])\n",
        "# plt.xticks(rotation=90)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ViDnMz7TAD6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # lemmatizing\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "# words_s_l = pd.Series(words_s).apply(lambda x: lemmatizer.lemmatize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kJhrl7A1BUcV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# words_s_l_p = pd.DataFrame(nltk.pos_tag(words_s_l), columns = ['words', 'pos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8DYdVpBKmTVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = ' '.join(words_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AsJQhbomoMrE",
        "colab_type": "code",
        "outputId": "4bdd579a-8ba2-457a-bf88-5285163eee89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's look at overall sentiment of the book\n",
        "scores = SentimentIntensityAnalyzer().polarity_scores(sentences)\n",
        "print(scores)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'neg': 0.074, 'neu': 0.801, 'pos': 0.125, 'compound': 0.9998}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SSUNj4Vvmlvs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving sentences as bigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mOzFfWFeIcV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def n_gram(x):\n",
        "  tokens = [token for token in x.split(\" \") if token != \"\"]\n",
        "  output = list(ngrams(tokens, 3))\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9UFroKIu37S",
        "colab_type": "code",
        "outputId": "edaa32d2-43bd-473c-9bec-7bfca445c3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pd.Series(sentences).apply(lambda x: n_gram(x))[0])\n",
        "\n",
        "# make a dataframe with 2 words as independent and just next third word as target column\n",
        "df = pd.concat([df[0] + ' ' + df[1], df[2]], axis = 1)\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the adveniure</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>adveniure of</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>of the</td>\n",
              "      <td>three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the three</td>\n",
              "      <td>i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>three i</td>\n",
              "      <td>think</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0      2\n",
              "0  the adveniure     of\n",
              "1   adveniure of    the\n",
              "2         of the  three\n",
              "3      the three      i\n",
              "4        three i  think"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "DTKJhyvkwAZq",
        "colab_type": "code",
        "outputId": "101ac5b7-17c1-4206-d243-bc2247f97458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "uVru8f_TweRE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfid = TfidfVectorizer()\n",
        "X = tfid.fit_transform(df[0]).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4acL1_QywuX2",
        "colab_type": "code",
        "outputId": "20e773bf-3d9e-4cf6-a595-9a44fb72c296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 1046)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "26ANsQQMxQky",
        "colab_type": "code",
        "outputId": "4ca46344-c6dc-4e48-eee3-8c564bc35a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "encoder = LabelBinarizer()\n",
        "y = encoder.fit_transform(df[2])\n",
        "y.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 1048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "ylGEDjd2wEfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTMs accept input in the form of (number_of_sequences, length_of_sequence, number_of_features)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFvbbAUg0fC4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(100, input_shape=(X.shape[1], X.shape[2]), return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(100, return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(100, return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(100, return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(100, return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(100))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8YtSD0kqjqxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "1002cbf1-f6ae-44b2-f9f5-0ae9b72092ce"
      },
      "cell_type": "code",
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.92.184.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 17276491466978196900)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3382443476736315270)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6749064115886791912)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4910787832089416217)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3718739855403276491)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6345859688227356255)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15754830196882749033)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2817945180242140059)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6970038780326950713)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9857695785483763215)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9809553847885456792)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qoZTpkZi2Wym",
        "colab_type": "code",
        "outputId": "5f1f3f1c-8000-4c77-8526-4c3dda6414d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4_input (InputLayer)    (None, 1046, 1)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 1046, 100)         40800     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1046, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 1046, 100)         80400     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 1046, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 1046, 100)         80400     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1046, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 1046, 100)         80400     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 1046, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_8 (LSTM)                (None, 1046, 100)         80400     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1046, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1048)              105848    \n",
            "=================================================================\n",
            "Total params: 548,648\n",
            "Trainable params: 548,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0oSrn4oL094A",
        "colab_type": "code",
        "outputId": "60c5af61-bb4b-4bdd-d5f8-5e03a766533c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1726
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.fit(X, y, epochs = 40, batch_size = 100)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(12,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(12, 1046, 1), dtype=tf.float32, name='lstm_4_input_10'), TensorSpec(shape=(12, 1048), dtype=tf.float32, name='dense_1_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for lstm_4_input\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f59f255b780> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 22.002034187316895 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.0010000000474974513 {0.001}\n",
            "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "4300/4446 [============================>.] - ETA: 4s - loss: 6.2661 - acc: 0.0484INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(5,), dtype=tf.int32, name='core_id_10'), TensorSpec(shape=(5, 1046, 1), dtype=tf.float32, name='lstm_4_input_10'), TensorSpec(shape=(5, 1048), dtype=tf.float32, name='dense_1_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for lstm_4_input\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f59f255b780> [<tf.Variable 'tpu_140024302308096/Adam/iterations:0' shape=() dtype=int64>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed2c15c0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed2c1e10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed2e7860>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed2a64e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed2697f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed235390>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed17b9b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed16af60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed134518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed07c320>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed043c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ed0386a0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecf7bda0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecf445f8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecf0e240>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59eced66d8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ece9fef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ece10828>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecdd84a8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecda07b8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecd68f28>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecd2ee10>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecc9efd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecc6afd0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecc312b0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecb7e278>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecb46898>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ecb33ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59eca7c208>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59eca43208>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59eca0db38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec9d6b38>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec9a04e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec90bb00>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec8d4128>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec89c278>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec866dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec7d5710>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec79ef98>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec766278>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec735e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec67b1d0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec669898>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec6324e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec57ddd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec543a20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec531898>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec4f74e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec440dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec409a20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec379898>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec3414e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec309dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec2d2a20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec23f898>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec2084e0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec1d0dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec199a20>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec105898>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59ec0ce4e0>]\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 37.488163471221924 secs\n",
            "4446/4446 [==============================] - 180s 41ms/sample - loss: 6.2609 - acc: 0.0481\n",
            "Epoch 2/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.7270 - acc: 0.0476\n",
            "Epoch 3/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6924 - acc: 0.0509\n",
            "Epoch 4/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6833 - acc: 0.0516\n",
            "Epoch 5/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6797 - acc: 0.0509\n",
            "Epoch 6/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6942 - acc: 0.0497\n",
            "Epoch 7/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6715 - acc: 0.0514\n",
            "Epoch 8/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6785 - acc: 0.0518\n",
            "Epoch 9/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6806 - acc: 0.0525\n",
            "Epoch 10/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6816 - acc: 0.0528\n",
            "Epoch 11/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6841 - acc: 0.0521\n",
            "Epoch 12/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6770 - acc: 0.0525\n",
            "Epoch 13/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6735 - acc: 0.0528\n",
            "Epoch 14/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6652 - acc: 0.0528\n",
            "Epoch 15/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6741 - acc: 0.0521\n",
            "Epoch 16/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6764 - acc: 0.0535\n",
            "Epoch 17/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6737 - acc: 0.0532\n",
            "Epoch 18/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6670 - acc: 0.0532\n",
            "Epoch 19/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6670 - acc: 0.0523\n",
            "Epoch 20/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6610 - acc: 0.0525\n",
            "Epoch 21/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6796 - acc: 0.0525\n",
            "Epoch 22/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6758 - acc: 0.0518\n",
            "Epoch 23/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6743 - acc: 0.0528\n",
            "Epoch 24/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6700 - acc: 0.0542\n",
            "Epoch 25/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6704 - acc: 0.0523\n",
            "Epoch 26/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6756 - acc: 0.0530\n",
            "Epoch 27/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6711 - acc: 0.0542\n",
            "Epoch 28/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6647 - acc: 0.0523\n",
            "Epoch 29/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6560 - acc: 0.0535\n",
            "Epoch 30/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6688 - acc: 0.0551\n",
            "Epoch 31/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6747 - acc: 0.0509\n",
            "Epoch 32/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6670 - acc: 0.0525\n",
            "Epoch 33/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6834 - acc: 0.0532\n",
            "Epoch 34/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6799 - acc: 0.0542\n",
            "Epoch 35/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6721 - acc: 0.0521\n",
            "Epoch 36/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6672 - acc: 0.0537\n",
            "Epoch 37/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6684 - acc: 0.0530\n",
            "Epoch 38/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6748 - acc: 0.0537\n",
            "Epoch 39/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6821 - acc: 0.0516\n",
            "Epoch 40/40\n",
            "4446/4446 [==============================] - 22s 5ms/sample - loss: 5.6733 - acc: 0.0521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59f54f3e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "oBzLht0_kH9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "2f618097-a71e-44e2-c7b5-bb0082324f1b"
      },
      "cell_type": "code",
      "source": [
        "cpu_model = tpu_model.sync_to_cpu()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mTjQYewI2uW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = cpu_model.predict(X[99:150])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "daCEJt_b4m-y",
        "colab_type": "code",
        "outputId": "57f2b958-20cb-4548-dabd-6a1e0319fe6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "cell_type": "code",
      "source": [
        "(encoder.inverse_transform(y_pred)).tolist()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "X__ogGyelVad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "36af7233-cd19-4aa8-8e42-d4a95b9ef485"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Evaluate the model on valid set\n",
        "score = cpu_model.evaluate(X, y, verbose = 0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Valid accuracy:', score[1])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Valid accuracy: 0.053081423\n",
            "CPU times: user 349 ms, sys: 42 ms, total: 391 ms\n",
            "Wall time: 2min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bKQ165TjrpN2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}