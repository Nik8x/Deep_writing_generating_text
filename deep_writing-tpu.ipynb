{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of deep_writing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nik8x/Deep_writing_generating_text/blob/master/deep_writing-tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RMw_d0K61LfB",
        "colab_type": "code",
        "outputId": "0a9371fc-9d59-46cf-8046-6fae50bd134e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import regex as re\n",
        "\n",
        "import nltk\n",
        "from nltk.draw.dispersion import dispersion_plot\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.probability import FreqDist\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.util import ngrams\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import urllib\n",
        "\n",
        "import os\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HyGRD5Ea1MgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(\"The current directory is: \", os.getcwd())\n",
        "# import os\n",
        "# os.chdir(\"/content/gdrive/My Drive/Galvanize Adm/Marcel Proust\")\n",
        "# print(\"The current directory is: \", os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oiOtYhrX1bM-",
        "colab_type": "code",
        "outputId": "41cda42a-dd2f-431d-cedf-0fc2908b324b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "txt = urllib.request.urlopen('http://www.textfiles.com/stories/3gables.txt').read().decode('utf8')\n",
        "txt = txt.replace('\\n', ' ')[322:]\n",
        "txt[0:400]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Adveniure of the Three Gables\\r \\r   I don't think that any of my adventures with Mr. Sherlock\\r Holmes opened quite so abruptly, or so dramatically, as that\\r which I associate with The Three Gables. I had not seen Holmes\\r for some days and had no idea of the new channel into which his\\r activities had been directed. He was in a chatty mood that\\r morning, however, and had just settled me into the \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "tu_M1Wo6hDTE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's do some cleaning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSHSwXGsiZQm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = txt.split(' ')\n",
        "words_s = [word.lower() for word in words if word.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3paoUv32pKW5",
        "colab_type": "code",
        "outputId": "5f6691ff-6c76-446a-b2e4-7232e6d08ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "len(words_s)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "kR1w_wAb1516",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# |# creating characters, words and lists \n",
        "# characters = sorted(list(set(txt)))\n",
        "# words = txt.split(' ')\n",
        "# sentences = txt.split('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0hqEFlkX9_fr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # let's remove stop words from words\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "# words_s = [i for i in words if not i in stop_words]\n",
        "# words_s = [word.lower() for word in words_s if word.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKmXGYHv_YoA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fdist = FreqDist(words_s) # checking most frequent words in whole document\n",
        "# plt.figure(figsize= (12,2))\n",
        "# plt.bar(pd.DataFrame(fdist.most_common()[0:20])[0], pd.DataFrame(fdist.most_common()[0:20])[1])\n",
        "# plt.xticks(rotation=90)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ViDnMz7TAD6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # lemmatizing\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "# words_s_l = pd.Series(words_s).apply(lambda x: lemmatizer.lemmatize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kJhrl7A1BUcV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# words_s_l_p = pd.DataFrame(nltk.pos_tag(words_s_l), columns = ['words', 'pos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8DYdVpBKmTVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = ' '.join(words_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AsJQhbomoMrE",
        "colab_type": "code",
        "outputId": "4bdd579a-8ba2-457a-bf88-5285163eee89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's look at overall sentiment of the book\n",
        "scores = SentimentIntensityAnalyzer().polarity_scores(sentences)\n",
        "print(scores)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'neg': 0.074, 'neu': 0.801, 'pos': 0.125, 'compound': 0.9998}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SSUNj4Vvmlvs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving sentences as bigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mOzFfWFeIcV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def n_gram(x):\n",
        "  tokens = [token for token in x.split(\" \") if token != \"\"]\n",
        "  output = list(ngrams(tokens, 3))\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9UFroKIu37S",
        "colab_type": "code",
        "outputId": "edaa32d2-43bd-473c-9bec-7bfca445c3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pd.Series(sentences).apply(lambda x: n_gram(x))[0])\n",
        "\n",
        "# make a dataframe with 2 words as independent and just next third word as target column\n",
        "df = pd.concat([df[0] + ' ' + df[1], df[2]], axis = 1)\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the adveniure</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>adveniure of</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>of the</td>\n",
              "      <td>three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the three</td>\n",
              "      <td>i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>three i</td>\n",
              "      <td>think</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0      2\n",
              "0  the adveniure     of\n",
              "1   adveniure of    the\n",
              "2         of the  three\n",
              "3      the three      i\n",
              "4        three i  think"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "DTKJhyvkwAZq",
        "colab_type": "code",
        "outputId": "101ac5b7-17c1-4206-d243-bc2247f97458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "uVru8f_TweRE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfid = TfidfVectorizer()\n",
        "X = tfid.fit_transform(df[0]).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4acL1_QywuX2",
        "colab_type": "code",
        "outputId": "20e773bf-3d9e-4cf6-a595-9a44fb72c296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 1046)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "26ANsQQMxQky",
        "colab_type": "code",
        "outputId": "4ca46344-c6dc-4e48-eee3-8c564bc35a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "encoder = LabelBinarizer()\n",
        "y = encoder.fit_transform(df[2])\n",
        "y.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 1048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "ylGEDjd2wEfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTMs accept input in the form of (number_of_sequences, length_of_sequence, number_of_features)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFvbbAUg0fC4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(400, input_shape=(X.shape[1], X.shape[2]), return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(400, return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "# model.add(tf.keras.layers.LSTM(2500, return_sequences = True))\n",
        "# model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(200))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8YtSD0kqjqxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "ed2a7a0e-5e2d-4e6f-9f83-d1453b948499"
      },
      "cell_type": "code",
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.92.184.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 17276491466978196900)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3382443476736315270)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6749064115886791912)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4910787832089416217)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3718739855403276491)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6345859688227356255)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15754830196882749033)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2817945180242140059)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6970038780326950713)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9857695785483763215)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9809553847885456792)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qoZTpkZi2Wym",
        "colab_type": "code",
        "outputId": "8ddcdd5b-0f8a-4baa-b931-ae654ae2748d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_25_input (InputLayer)   (None, 1046, 1)           0         \n",
            "_________________________________________________________________\n",
            "lstm_25 (LSTM)               (None, 1046, 400)         643200    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 1046, 400)         0         \n",
            "_________________________________________________________________\n",
            "lstm_26 (LSTM)               (None, 1046, 400)         1281600   \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 1046, 400)         0         \n",
            "_________________________________________________________________\n",
            "lstm_27 (LSTM)               (None, 200)               480800    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1048)              210648    \n",
            "=================================================================\n",
            "Total params: 2,616,248\n",
            "Trainable params: 2,616,248\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0oSrn4oL094A",
        "colab_type": "code",
        "outputId": "53d4bc52-a677-47bc-a525-d744870e3fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1726
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.fit(X, y, epochs = 40, batch_size = 100)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(12,), dtype=tf.int32, name='core_id_50'), TensorSpec(shape=(12, 1046, 1), dtype=tf.float32, name='lstm_25_input_10'), TensorSpec(shape=(12, 1048), dtype=tf.float32, name='dense_5_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for lstm_25_input\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f59c79bae80> []\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 94.80062794685364 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "INFO:tensorflow:CPU -> TPU lr: 0.0010000000474974513 {0.001}\n",
            "INFO:tensorflow:CPU -> TPU beta_1: 0.8999999761581421 {0.9}\n",
            "INFO:tensorflow:CPU -> TPU beta_2: 0.9990000128746033 {0.999}\n",
            "INFO:tensorflow:CPU -> TPU decay: 0.0 {0.0}\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n",
            "4300/4446 [============================>.] - ETA: 16s - loss: 6.1423 - acc: 0.0390INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(5,), dtype=tf.int32, name='core_id_50'), TensorSpec(shape=(5, 1046, 1), dtype=tf.float32, name='lstm_25_input_10'), TensorSpec(shape=(5, 1048), dtype=tf.float32, name='dense_5_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for lstm_25_input\n",
            "INFO:tensorflow:KerasCrossShard: <tensorflow.python.keras.optimizers.Adam object at 0x7f59c79bae80> [<tf.Variable 'tpu_140023583116760/Adam/iterations:0' shape=() dtype=int64>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4e09550>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4e09ef0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4e2f320>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4dee860>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4d386d8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4d295f8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4c759e8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4c3e668>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4c0b358>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4bd6978>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4b49f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4b17b70>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4ae27f0>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4aadac8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4a20f60>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c49eb390>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4935320>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4902b00>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c48f3780>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c483d518>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4809320>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c47d6c50>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4751dd8>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4716940>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c46e2588>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c46ade48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c45f8860>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c45eb908>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4537550>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c4502e48>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c44cd860>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c443f908>, <tensorflow.contrib.tpu.python.tpu.keras_tpu_variables.ReplicatedVariable object at 0x7f59c440d550>]\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 134.4557011127472 secs\n",
            "4446/4446 [==============================] - 662s 149ms/sample - loss: 6.1388 - acc: 0.0394\n",
            "Epoch 2/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7489 - acc: 0.0488\n",
            "Epoch 3/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7165 - acc: 0.0476\n",
            "Epoch 4/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7184 - acc: 0.0495\n",
            "Epoch 5/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7005 - acc: 0.0528\n",
            "Epoch 6/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7102 - acc: 0.0481\n",
            "Epoch 7/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7093 - acc: 0.0495\n",
            "Epoch 8/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7055 - acc: 0.0521\n",
            "Epoch 9/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7041 - acc: 0.0521\n",
            "Epoch 10/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.6989 - acc: 0.0523\n",
            "Epoch 11/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7085 - acc: 0.0514\n",
            "Epoch 12/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7124 - acc: 0.0525\n",
            "Epoch 13/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7101 - acc: 0.0500\n",
            "Epoch 14/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7141 - acc: 0.0521\n",
            "Epoch 15/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.6950 - acc: 0.0514\n",
            "Epoch 16/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7166 - acc: 0.0528\n",
            "Epoch 17/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7148 - acc: 0.0521\n",
            "Epoch 18/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7229 - acc: 0.0525\n",
            "Epoch 19/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7137 - acc: 0.0514\n",
            "Epoch 20/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7163 - acc: 0.0535\n",
            "Epoch 21/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7156 - acc: 0.0521\n",
            "Epoch 22/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7101 - acc: 0.0511\n",
            "Epoch 23/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7260 - acc: 0.0523\n",
            "Epoch 24/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7160 - acc: 0.0530\n",
            "Epoch 25/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7181 - acc: 0.0476\n",
            "Epoch 26/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7226 - acc: 0.0530\n",
            "Epoch 27/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7249 - acc: 0.0523\n",
            "Epoch 28/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7201 - acc: 0.0530\n",
            "Epoch 29/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7223 - acc: 0.0539\n",
            "Epoch 30/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7182 - acc: 0.0500\n",
            "Epoch 31/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7112 - acc: 0.0488\n",
            "Epoch 32/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7042 - acc: 0.0523\n",
            "Epoch 33/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7125 - acc: 0.0544\n",
            "Epoch 34/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7082 - acc: 0.0521\n",
            "Epoch 35/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7226 - acc: 0.0528\n",
            "Epoch 36/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7158 - acc: 0.0530\n",
            "Epoch 37/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7202 - acc: 0.0507\n",
            "Epoch 38/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7186 - acc: 0.0535\n",
            "Epoch 39/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7253 - acc: 0.0495\n",
            "Epoch 40/40\n",
            "4446/4446 [==============================] - 30s 7ms/sample - loss: 5.7139 - acc: 0.0530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59c9863cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "oBzLht0_kH9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "5881ba56-fc4b-4a67-a411-737b76c65fd0"
      },
      "cell_type": "code",
      "source": [
        "cpu_model = tpu_model.sync_to_cpu()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mTjQYewI2uW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = cpu_model.predict(X[99:150])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "daCEJt_b4m-y",
        "colab_type": "code",
        "outputId": "6977bb37-f764-4562-de59-cb1bd79b00fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "cell_type": "code",
      "source": [
        "(encoder.inverse_transform(y_pred)).tolist()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'i',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'to',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "X__ogGyelVad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c5afad0a-410f-4497-a68c-765afc6e5e92"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Evaluate the model on valid set\n",
        "score = cpu_model.evaluate(X, y, verbose = 0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Valid accuracy:', score[1])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Valid accuracy: 0.05263158\n",
            "CPU times: user 418 ms, sys: 52.1 ms, total: 470 ms\n",
            "Wall time: 5min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bKQ165TjrpN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ecb59b6f-be00-4e02-e534-b1431b597a0a"
      },
      "cell_type": "code",
      "source": [
        "(encoder.inverse_transform(cpu_model.predict(X[1200:1201])))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['the'], dtype='<U13')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    }
  ]
}