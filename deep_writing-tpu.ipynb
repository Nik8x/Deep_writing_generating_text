{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of deep_writing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nik8x/Deep_writing_generating_text/blob/master/deep_writing-tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RMw_d0K61LfB",
        "colab_type": "code",
        "outputId": "0a9371fc-9d59-46cf-8046-6fae50bd134e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import regex as re\n",
        "\n",
        "import nltk\n",
        "from nltk.draw.dispersion import dispersion_plot\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.probability import FreqDist\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.util import ngrams\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import urllib\n",
        "\n",
        "import os\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HyGRD5Ea1MgY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(\"The current directory is: \", os.getcwd())\n",
        "# import os\n",
        "# os.chdir(\"/content/gdrive/My Drive/Galvanize Adm/Marcel Proust\")\n",
        "# print(\"The current directory is: \", os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oiOtYhrX1bM-",
        "colab_type": "code",
        "outputId": "41cda42a-dd2f-431d-cedf-0fc2908b324b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "txt = urllib.request.urlopen('http://www.textfiles.com/stories/3gables.txt').read().decode('utf8')\n",
        "txt = txt.replace('\\n', ' ')[322:]\n",
        "txt[0:400]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Adveniure of the Three Gables\\r \\r   I don't think that any of my adventures with Mr. Sherlock\\r Holmes opened quite so abruptly, or so dramatically, as that\\r which I associate with The Three Gables. I had not seen Holmes\\r for some days and had no idea of the new channel into which his\\r activities had been directed. He was in a chatty mood that\\r morning, however, and had just settled me into the \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "tu_M1Wo6hDTE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's do some cleaning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSHSwXGsiZQm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = txt.split(' ')\n",
        "words_s = [word.lower() for word in words if word.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3paoUv32pKW5",
        "colab_type": "code",
        "outputId": "5f6691ff-6c76-446a-b2e4-7232e6d08ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "len(words_s)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4448"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "kR1w_wAb1516",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# |# creating characters, words and lists \n",
        "# characters = sorted(list(set(txt)))\n",
        "# words = txt.split(' ')\n",
        "# sentences = txt.split('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0hqEFlkX9_fr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # let's remove stop words from words\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "# words_s = [i for i in words if not i in stop_words]\n",
        "# words_s = [word.lower() for word in words_s if word.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKmXGYHv_YoA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fdist = FreqDist(words_s) # checking most frequent words in whole document\n",
        "# plt.figure(figsize= (12,2))\n",
        "# plt.bar(pd.DataFrame(fdist.most_common()[0:20])[0], pd.DataFrame(fdist.most_common()[0:20])[1])\n",
        "# plt.xticks(rotation=90)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ViDnMz7TAD6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # lemmatizing\n",
        "# lemmatizer = WordNetLemmatizer()\n",
        "# words_s_l = pd.Series(words_s).apply(lambda x: lemmatizer.lemmatize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kJhrl7A1BUcV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# words_s_l_p = pd.DataFrame(nltk.pos_tag(words_s_l), columns = ['words', 'pos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8DYdVpBKmTVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = ' '.join(words_s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AsJQhbomoMrE",
        "colab_type": "code",
        "outputId": "4bdd579a-8ba2-457a-bf88-5285163eee89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's look at overall sentiment of the book\n",
        "scores = SentimentIntensityAnalyzer().polarity_scores(sentences)\n",
        "print(scores)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'neg': 0.074, 'neu': 0.801, 'pos': 0.125, 'compound': 0.9998}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SSUNj4Vvmlvs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# saving sentences as bigrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mOzFfWFeIcV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def n_gram(x):\n",
        "  tokens = [token for token in x.split(\" \") if token != \"\"]\n",
        "  output = list(ngrams(tokens, 3))\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9UFroKIu37S",
        "colab_type": "code",
        "outputId": "edaa32d2-43bd-473c-9bec-7bfca445c3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pd.Series(sentences).apply(lambda x: n_gram(x))[0])\n",
        "\n",
        "# make a dataframe with 2 words as independent and just next third word as target column\n",
        "df = pd.concat([df[0] + ' ' + df[1], df[2]], axis = 1)\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the adveniure</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>adveniure of</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>of the</td>\n",
              "      <td>three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the three</td>\n",
              "      <td>i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>three i</td>\n",
              "      <td>think</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               0      2\n",
              "0  the adveniure     of\n",
              "1   adveniure of    the\n",
              "2         of the  three\n",
              "3      the three      i\n",
              "4        three i  think"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "DTKJhyvkwAZq",
        "colab_type": "code",
        "outputId": "101ac5b7-17c1-4206-d243-bc2247f97458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "uVru8f_TweRE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfid = TfidfVectorizer()\n",
        "X = tfid.fit_transform(df[0]).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4acL1_QywuX2",
        "colab_type": "code",
        "outputId": "20e773bf-3d9e-4cf6-a595-9a44fb72c296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 1046)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "26ANsQQMxQky",
        "colab_type": "code",
        "outputId": "4ca46344-c6dc-4e48-eee3-8c564bc35a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "encoder = LabelBinarizer()\n",
        "y = encoder.fit_transform(df[2])\n",
        "y.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4446, 1048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "ylGEDjd2wEfD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LSTMs accept input in the form of (number_of_sequences, length_of_sequence, number_of_features)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LFvbbAUg0fC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "c5464346-3e98-41de-e51d-7aabb5fde218"
      },
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.LSTM(100, input_shape=(X.shape[1], X.shape[2]), return_sequences = True))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.LSTM(100))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8YtSD0kqjqxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "3e712771-d7dc-44fc-b084-9448d32b5ae4"
      },
      "cell_type": "code",
      "source": [
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.92.184.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 17276491466978196900)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3382443476736315270)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6749064115886791912)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4910787832089416217)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3718739855403276491)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 6345859688227356255)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15754830196882749033)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 2817945180242140059)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6970038780326950713)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9857695785483763215)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9809553847885456792)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qoZTpkZi2Wym",
        "colab_type": "code",
        "outputId": "10945797-143d-4143-9bdf-c0fbc45b793a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_input (InputLayer)      (None, 1046, 1)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 1046, 100)         40800     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1046, 100)         0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1048)              105848    \n",
            "=================================================================\n",
            "Total params: 227,048\n",
            "Trainable params: 227,048\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0oSrn4oL094A",
        "colab_type": "code",
        "outputId": "2b05c835-cfae-4327-af7c-97abc6c8f4a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1706
        }
      },
      "cell_type": "code",
      "source": [
        "tpu_model.fit(X, y, epochs = 50, batch_size = 100)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.7419 - acc: 0.0446\n",
            "Epoch 2/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6961 - acc: 0.0509\n",
            "Epoch 3/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6964 - acc: 0.0518\n",
            "Epoch 4/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6798 - acc: 0.0523\n",
            "Epoch 5/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6826 - acc: 0.0514\n",
            "Epoch 6/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6688 - acc: 0.0497\n",
            "Epoch 7/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6727 - acc: 0.0516\n",
            "Epoch 8/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6657 - acc: 0.0532\n",
            "Epoch 9/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6652 - acc: 0.0546\n",
            "Epoch 10/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6599 - acc: 0.0537\n",
            "Epoch 11/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6684 - acc: 0.0532\n",
            "Epoch 12/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6664 - acc: 0.0537\n",
            "Epoch 13/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6638 - acc: 0.0535\n",
            "Epoch 14/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6646 - acc: 0.0523\n",
            "Epoch 15/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6678 - acc: 0.0530\n",
            "Epoch 16/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6713 - acc: 0.0537\n",
            "Epoch 17/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6712 - acc: 0.0535\n",
            "Epoch 18/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6592 - acc: 0.0525\n",
            "Epoch 19/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6719 - acc: 0.0523\n",
            "Epoch 20/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6653 - acc: 0.0528\n",
            "Epoch 21/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6762 - acc: 0.0514\n",
            "Epoch 22/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6614 - acc: 0.0539\n",
            "Epoch 23/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6630 - acc: 0.0532\n",
            "Epoch 24/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6723 - acc: 0.0535\n",
            "Epoch 25/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6657 - acc: 0.0537\n",
            "Epoch 26/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6639 - acc: 0.0532\n",
            "Epoch 27/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6689 - acc: 0.0542\n",
            "Epoch 28/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6651 - acc: 0.0523\n",
            "Epoch 29/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6618 - acc: 0.0532\n",
            "Epoch 30/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6737 - acc: 0.0516\n",
            "Epoch 31/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6687 - acc: 0.0528\n",
            "Epoch 32/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6784 - acc: 0.0518\n",
            "Epoch 33/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6679 - acc: 0.0537\n",
            "Epoch 34/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6739 - acc: 0.0528\n",
            "Epoch 35/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6548 - acc: 0.0539\n",
            "Epoch 36/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6719 - acc: 0.0535\n",
            "Epoch 37/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6684 - acc: 0.0530\n",
            "Epoch 38/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6652 - acc: 0.0532\n",
            "Epoch 39/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6684 - acc: 0.0542\n",
            "Epoch 40/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6736 - acc: 0.0537\n",
            "Epoch 41/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6696 - acc: 0.0530\n",
            "Epoch 42/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6702 - acc: 0.0528\n",
            "Epoch 43/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6612 - acc: 0.0537\n",
            "Epoch 44/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6653 - acc: 0.0530\n",
            "Epoch 45/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6691 - acc: 0.0532\n",
            "Epoch 46/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6652 - acc: 0.0535\n",
            "Epoch 47/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6598 - acc: 0.0542\n",
            "Epoch 48/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6639 - acc: 0.0528\n",
            "Epoch 49/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6545 - acc: 0.0539\n",
            "Epoch 50/50\n",
            "4446/4446 [==============================] - 7s 2ms/sample - loss: 5.6553 - acc: 0.0530\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f59f5845d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "oBzLht0_kH9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "93f61014-daea-414c-8763-19f3d019010b"
      },
      "cell_type": "code",
      "source": [
        "cpu_model = tpu_model.sync_to_cpu()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "INFO:tensorflow:TPU -> CPU lr: 0.0010000000474974513\n",
            "INFO:tensorflow:TPU -> CPU beta_1: 0.8999999761581421\n",
            "INFO:tensorflow:TPU -> CPU beta_2: 0.9990000128746033\n",
            "INFO:tensorflow:TPU -> CPU decay: 0.0\n",
            "INFO:tensorflow:TPU -> CPU epsilon: 1e-07\n",
            "WARNING:tensorflow:Cannot update non-variable config: epsilon\n",
            "INFO:tensorflow:TPU -> CPU amsgrad: False\n",
            "WARNING:tensorflow:Cannot update non-variable config: amsgrad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mTjQYewI2uW0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = cpu_model.predict(X[99:150])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "daCEJt_b4m-y",
        "colab_type": "code",
        "outputId": "bb76eed6-7e51-4afa-fbbd-ba03d00282a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "cell_type": "code",
      "source": [
        "(encoder.inverse_transform(y_pred)).tolist()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the',\n",
              " 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "X__ogGyelVad",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d3fbb689-1eae-4b31-d88a-19688ccb42a2"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Evaluate the model on valid set\n",
        "score = cpu_model.evaluate(X, y, verbose = 0)\n",
        "\n",
        "# Print test accuracy\n",
        "print('\\n', 'Valid accuracy:', score[1])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Valid accuracy: 0.053081423\n",
            "CPU times: user 251 ms, sys: 41.6 ms, total: 293 ms\n",
            "Wall time: 49.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}